{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation using Decision Trees and Logistic Regression (with Scaling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook uses cross-validation for evaluation of model performing, using 2 Machine Learning Classification Models: Decision Tree and Logistic Regression (with scaling applied to the input data).\n",
    "\n",
    "## Approach\n",
    "* Evaluations of classification performed were performed using 2 sample datasets:\n",
    "    * sklearn's Iris sample dataset, consisting of 150 sample data points for 3 varieties of iris flowers\n",
    "    * voice dataset, containing 3168 sample data points of male and female speakers\n",
    "\n",
    "* Performance was evaluated based upon:\n",
    "    * Classification model score for the test data\n",
    "    * Time required to fit the model with training data\n",
    "    \n",
    "* For each Classification model, evaluations were performed with tuning of key parameters:\n",
    "    * Decision Tree: Maximum Tree Depth\n",
    "    * Logistic Regression: Solver algorithm\n",
    "    \n",
    "## Results\n",
    "* Refer to the Figure and Table of Evaluation results provided below\n",
    "* Both Decision Tree and Logistic Regression models performed well for both the Iris and Voice datasets, with Decision Tree show a significant decrease in performance only when Maximum Tree Depth was severely restricted.\n",
    "* For these datasets, the Decision Tree classifier model fit the data more quickly than the Logistic Regression classifier for comparable performance levels.\n",
    "* The Decision Tree classifier showed significant degradation in performance when Maximum Tree Depth was restricted when using the Iris dataset (4 features, 1 output with 3 classes), but showed almost no degradation in performance with Max Tree Depth restricted when using the Voice dataset (20 features, 1 output with 2 classes).  This classifier required much more fit time with the Voice dataset vs. the Iris dataset.  An examination of decision trees generated for each dataset might provide insight on these observations.\n",
    "* The Logistic Regression classifier required more fit time than all but the slowest tests with the Decision Tree classifier.  The fastest Fit Time was obtained using lbfgs solver for the Iris dataset and liblinear solver for the Voice dataset.  Investigating the algorithmic differences in these solvers may provide some explanation of both the fit time differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Figure: Classification Model Performance: Decision Tree vs. Logistic Regression |\n",
    "| :----------: |\n",
    "| ![Figure: Classification Model Performance: Decision Tree vs. Logistic Regression is Loading...](docs/Figure-Comparison_DecisionTree_vs_LogisticRegression.png \"Figure: Classification Model Performance: Decision Tree vs. Logistic Regression\") |\n",
    "\n",
    "| Table: Classification Model Performance: Decision Tree vs. Logistic Regression |\n",
    "| :----------: |\n",
    "| ![Table: Classification Model Performance: Decision Tree vs. Logistic Regression is Loading...](docs/Table-Comparison_DecisionTree_vs_LogisticRegression.png \"Figure: Classification Model Performance: Decision Tree vs. Logistic Regression\") |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbpresent": {
     "id": "828c2e12-b1c6-4994-8f55-ce86373b6c97"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# %matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D    # Support 3D graphing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# Visualization\n",
    "import graphviz\n",
    "import pydotplus\n",
    "\n",
    "# Machine Learning - Linear Models - Regression\n",
    "from sklearn.linear_model import LinearRegression  # TBD\n",
    "from sklearn.linear_model import Lasso             # TBD\n",
    "from sklearn.linear_model import Ridge             # TBD\n",
    "from sklearn.linear_model import ElasticNet        # TBD\n",
    "\n",
    "# Machine Learning - Linear Models - Classification\n",
    "from sklearn.linear_model import LogisticRegression   # Linear model for classification\n",
    "\n",
    "# Machine Learning - Decision Trees and Random Forests - Classification\n",
    "from sklearn import tree                             # Decision Tree Classifer\n",
    "from sklearn.ensemble import RandomForestClassifier  # Random Forest Classifer\n",
    "\n",
    "# Machine Learning - Data Preparation and Pre-Processing\n",
    "from sklearn.model_selection import train_test_split # Split data into training and testing samples\n",
    "from sklearn.model_selection import cross_val_score  # Score a model using k-fold or other cross validation\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder   # Convert categorical integer features (X) to One-Hot encoded values\n",
    "from sklearn.preprocessing import LabelEncoder    # Convert categorical labeled values to categorical integer values\n",
    "from sklearn.preprocessing import LabelBinarizer  # Convert categorical labeled values to Binary encoded values\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler  # Scale numerical features to standard normal distribution\n",
    "from sklearn.preprocessing import MinMaxScaler    # Scale numerical values based upon mix/max values\n",
    "\n",
    "# Machine Learning - Quantify Model Performance\n",
    "from sklearn.metrics import mean_squared_error   # Mean Squared Error (MSE) metric\n",
    "from sklearn.metrics import r2_score             # R-squared (Coefficient of Determination) metric\n",
    "from sklearn.metrics import confusion_matrix     # Generate a confusion matrix (actual vs. predicted counts)\n",
    "\n",
    "# Machine Learning - Dataset Generation\n",
    "from sklearn.datasets import make_regression     # Generate linear data\n",
    "from sklearn.datasets import make_s_curve        # Generate nonlinear data\n",
    "from sklearn.datasets import make_blobs          # Generate blobs for classification\n",
    "from sklearn.datasets import make_circles        # Generate circles for classification\n",
    "from sklearn.datasets import load_iris           # Sample multi-class dataset for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Model Comparison: Decision Tree vs Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])\n",
      "Feature Names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "Target Names: ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "# Import the Iris sample dataset as a dictionary\n",
    "iris = load_iris()\n",
    "\n",
    "print( f\"Iris {iris.keys()}\" )\n",
    "print( f\"Feature Names: {iris.feature_names}\" )\n",
    "print( f\"Target Names: {iris.target_names}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4) (150,)\n"
     ]
    }
   ],
   "source": [
    "# Assign data and target variables\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "print( X.shape, y.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data using train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 1) (38, 1)\n"
     ]
    }
   ],
   "source": [
    "# Reshape the outputs to provide a N by 1 vector (vs. array of size N)\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dadja\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# Use the training data to create a scaler to standard normal distributions for each numerical feature and output\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "y_scaler = StandardScaler().fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dadja\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\dadja\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# Scale the training and test data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "y_train_scaled = y_scaler.transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model: Logistic Regression - Iris Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression: Function to Fit Model, Evaluate Performance - Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fit a model to training data, calculate predictions, and create a residuals chart\n",
    "# No cross-validation\n",
    "def eval_logisticregression(a_model):\n",
    "    # Get the name of this model\n",
    "    m_name = str(a_model).split(\"(\",1)[0]\n",
    "    \n",
    "    # Get the solver used with this model\n",
    "    m_solver = str(a_model).split(\"solver=\")[1].split(\",\")[0].replace(\"'\",\"\").replace('\"','')\n",
    "    \n",
    "    # Print a separator\n",
    "    print(\"*\"*80)\n",
    "    \n",
    "    # Print the model attributes\n",
    "    print(a_model)\n",
    "    \n",
    "    # Fit the data to the scaled data\n",
    "    m_fit_time = %timeit -n1 -r1 -o a_model.fit(X_train, y_train)\n",
    "\n",
    "    # Calculate Model performance: MSE and R2\n",
    "    m_score_test = a_model.score(X_test, y_test)\n",
    "    m_score_train = a_model.score(X_train, y_train)\n",
    "\n",
    "    print(f\"Performance - Model: {m_name}\\nScore - Test Data: {m_score_test}, Training Data: {m_score_train}\")\n",
    "    print(f\"coef_: {a_model.coef_}, intercept_: {a_model.intercept_}, n_iter_: {a_model.n_iter_}, \")\n",
    "\n",
    "    # Make predictions using both test and training data\n",
    "    y_predicted_test = a_model.predict(X_test)\n",
    "    y_predicted_train = a_model.predict(X_train)\n",
    "    \n",
    "    # Generate a confusion matrix of the results for both test and training data\n",
    "    cm_test = confusion_matrix(y_test, y_predicted_test)\n",
    "    print(\"\\nConfusion Matrix - Testing Data\")\n",
    "    print(cm_test)\n",
    "\n",
    "    cm_train = confusion_matrix(y_train, y_predicted_train)\n",
    "    print(\"\\nConfusion Matrix - Training Data\")\n",
    "    print(cm_train)\n",
    "        \n",
    "    a_result = {\n",
    "        'model': m_name,\n",
    "        'solver': m_solver,\n",
    "        'fit_time': m_fit_time.average,\n",
    "        'n_iter': a_model.n_iter_,\n",
    "        'score_test': m_score_test,\n",
    "        'score_train': m_score_train\n",
    "    }\n",
    "    \n",
    "    return a_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fit a model to training data, calculate predictions, and create a residuals chart\n",
    "# With scaling for the input data (X) only; leave y as categorical integers\n",
    "def eval_logisticregression_scaled(a_model):\n",
    "    # Get the name of this model\n",
    "    m_name = str(a_model).split(\"(\",1)[0]\n",
    "    \n",
    "    # Get the solver used with this model\n",
    "    m_solver = str(a_model).split(\"solver=\")[1].split(\",\")[0].replace(\"'\",\"\").replace('\"','')\n",
    "    \n",
    "    # Print a separator\n",
    "    print(\"*\"*80)\n",
    "    \n",
    "    # Print the model attributes\n",
    "    print(a_model)\n",
    "    \n",
    "    # Fit the data to the scaled data\n",
    "    m_fit_time = %timeit -n1 -r1 -o a_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Calculate Model performance: MSE and R2\n",
    "    m_score_test = a_model.score(X_test_scaled, y_test)\n",
    "    m_score_train = a_model.score(X_train_scaled, y_train)\n",
    "\n",
    "    print(f\"Performance - Model: {m_name}\\nScore - Test Data: {m_score_test}, Training Data: {m_score_train}\")\n",
    "    print(f\"coef_: {a_model.coef_}, intercept_: {a_model.intercept_}, n_iter_: {a_model.n_iter_}, \")\n",
    "\n",
    "    # Make predictions using both test and training data\n",
    "    y_predicted_test = a_model.predict(X_test_scaled)\n",
    "    y_predicted_train = a_model.predict(X_train_scaled)\n",
    "    \n",
    "    # Generate a confusion matrix of the results for both test and training data\n",
    "    cm_test = confusion_matrix(y_test, y_predicted_test)\n",
    "    print(\"\\nConfusion Matrix - Testing Data\")\n",
    "    print(cm_test)\n",
    "\n",
    "    cm_train = confusion_matrix(y_train, y_predicted_train)\n",
    "    print(\"\\nConfusion Matrix - Training Data\")\n",
    "    print(cm_train)\n",
    "        \n",
    "    a_result = {\n",
    "        'model': m_name,\n",
    "        'solver': m_solver,\n",
    "        'fit_time': m_fit_time.average,\n",
    "        'n_iter': a_model.n_iter_,\n",
    "        'score_test': m_score_test,\n",
    "        'score_train': m_score_train\n",
    "    }\n",
    "    \n",
    "    return a_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression: Iterate Model Parameter - Solver - Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=1000, multi_class='warn', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "22.8 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "Performance - Model: LogisticRegression\n",
      "Score - Test Data: 0.9473684210526315, Training Data: 0.9642857142857143\n",
      "coef_: [[ 0.3907117   1.37436878 -2.13767942 -0.96016737]\n",
      " [ 0.23278187 -1.35332939  0.53906796 -1.07848056]\n",
      " [-1.4455873  -1.42046371  2.2047123   2.14288415]], intercept_: [ 0.24210889  1.19565428 -1.14320743], n_iter_: [7], \n",
      "\n",
      "Confusion Matrix - Testing Data\n",
      "[[12  0  0]\n",
      " [ 0 11  2]\n",
      " [ 0  0 13]]\n",
      "\n",
      "Confusion Matrix - Training Data\n",
      "[[38  0  0]\n",
      " [ 0 33  4]\n",
      " [ 0  0 37]]\n",
      "\n",
      "********************************************************************************\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=1000, multi_class='warn', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "24.5 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "Performance - Model: LogisticRegression\n",
      "Score - Test Data: 0.9473684210526315, Training Data: 0.9464285714285714\n",
      "coef_: [[-0.43420969  0.83449698 -2.20347845 -0.92353627]\n",
      " [-0.75237944 -1.99675264  0.76341967 -0.83915003]\n",
      " [ 0.33958389 -0.42892094  2.54412261  1.83571066]], intercept_: [  6.45860731   7.77439646 -16.47380486], n_iter_: [12 14 14], \n",
      "\n",
      "Confusion Matrix - Testing Data\n",
      "[[12  0  0]\n",
      " [ 0 12  1]\n",
      " [ 0  1 12]]\n",
      "\n",
      "Confusion Matrix - Training Data\n",
      "[[38  0  0]\n",
      " [ 0 32  5]\n",
      " [ 0  1 36]]\n",
      "\n",
      "********************************************************************************\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=1000, multi_class='warn', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "15.7 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "Performance - Model: LogisticRegression\n",
      "Score - Test Data: 0.9473684210526315, Training Data: 0.9464285714285714\n",
      "coef_: [[-0.43417222  0.83441302 -2.20351232 -0.92355602]\n",
      " [-0.75236474 -1.99674719  0.7634091  -0.83914755]\n",
      " [ 0.33956507 -0.42880388  2.54415672  1.83570939]], intercept_: [  6.45877245   7.77433564 -16.47419279], n_iter_: [32 35 31], \n",
      "\n",
      "Confusion Matrix - Testing Data\n",
      "[[12  0  0]\n",
      " [ 0 12  1]\n",
      " [ 0  1 12]]\n",
      "\n",
      "Confusion Matrix - Training Data\n",
      "[[38  0  0]\n",
      " [ 0 32  5]\n",
      " [ 0  1 36]]\n",
      "\n",
      "********************************************************************************\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=1000, multi_class='warn', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dadja\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dadja\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\dadja\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dadja\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\dadja\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dadja\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\dadja\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dadja\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\dadja\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "Performance - Model: LogisticRegression\n",
      "Score - Test Data: 0.9473684210526315, Training Data: 0.9375\n",
      "coef_: [[-0.18412397  0.99620892 -2.17123603 -0.92876292]\n",
      " [-0.71255906 -1.96797845  0.75403333 -0.84861283]\n",
      " [ 0.04743548 -0.58155576  2.41562774  1.85969263]], intercept_: [  4.54622389   7.50259924 -13.59565324], n_iter_: [1000  640 1000], \n",
      "\n",
      "Confusion Matrix - Testing Data\n",
      "[[12  0  0]\n",
      " [ 0 12  1]\n",
      " [ 0  1 12]]\n",
      "\n",
      "Confusion Matrix - Training Data\n",
      "[[38  0  0]\n",
      " [ 0 31  6]\n",
      " [ 0  1 36]]\n",
      "\n",
      "********************************************************************************\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=1000, multi_class='warn', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='saga', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "82.2 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "Performance - Model: LogisticRegression\n",
      "Score - Test Data: 0.9736842105263158, Training Data: 0.9375\n",
      "coef_: [[ 0.0245857   1.13212144 -2.15325624 -0.93740718]\n",
      " [-0.66374414 -1.93306723  0.74254132 -0.86022359]\n",
      " [-0.32549004 -0.78534466  2.29423221  1.91152577]], intercept_: [  2.97242944   7.17022951 -10.13967048], n_iter_: [1000 1000 1000], \n",
      "\n",
      "Confusion Matrix - Testing Data\n",
      "[[12  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  1 12]]\n",
      "\n",
      "Confusion Matrix - Training Data\n",
      "[[38  0  0]\n",
      " [ 0 31  6]\n",
      " [ 0  1 36]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dadja\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dadja\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\dadja\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Initialize list of dictionary of results for summary in a dataframe later\n",
    "model_results = []\n",
    "\n",
    "# List of Solvers to use with LogisticRegression model\n",
    "solver_list = \"liblinear\", \"newton-cg\", \"lbfgs\", \"sag\", \"saga\"\n",
    "\n",
    "# Generate classifer and an associated performance report for each\n",
    "for s in solver_list:\n",
    "    # Create a classifier model\n",
    "    classifier = LogisticRegression(solver=s, n_jobs=1, max_iter=1000)\n",
    "    \n",
    "    # Evaluate the classifer performance, create a plot of \n",
    "    r = eval_logisticregression(classifier)\n",
    "#     r = eval_logisticregression_scaled(classifier)\n",
    "    model_results.append( {\n",
    "        'Dataset': 'Iris',\n",
    "        'Classifier': r['model'],\n",
    "        'Solver': r['solver'],\n",
    "        'Fit Time (ms)': 1000.0*r['fit_time'],\n",
    "        'Iterations': r['n_iter'],\n",
    "        'Total Iterations': sum(r['n_iter']),\n",
    "        'Score-Testing Data': r['score_test'],\n",
    "        'Score-Training Data': r['score_train'] } )\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression: Summary - Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Solver</th>\n",
       "      <th>Fit Time (ms)</th>\n",
       "      <th>Iterations</th>\n",
       "      <th>Total Iterations</th>\n",
       "      <th>Score-Testing Data</th>\n",
       "      <th>Score-Training Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>22.8474</td>\n",
       "      <td>[7]</td>\n",
       "      <td>7</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.964286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iris</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>24.4624</td>\n",
       "      <td>[12, 14, 14]</td>\n",
       "      <td>40</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.946429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iris</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>15.7461</td>\n",
       "      <td>[32, 35, 31]</td>\n",
       "      <td>98</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.946429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iris</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>sag</td>\n",
       "      <td>100.4382</td>\n",
       "      <td>[1000, 640, 1000]</td>\n",
       "      <td>2640</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iris</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>saga</td>\n",
       "      <td>82.2359</td>\n",
       "      <td>[1000, 1000, 1000]</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset          Classifier     Solver  Fit Time (ms)          Iterations  \\\n",
       "0    Iris  LogisticRegression  liblinear        22.8474                 [7]   \n",
       "1    Iris  LogisticRegression  newton-cg        24.4624        [12, 14, 14]   \n",
       "2    Iris  LogisticRegression      lbfgs        15.7461        [32, 35, 31]   \n",
       "3    Iris  LogisticRegression        sag       100.4382   [1000, 640, 1000]   \n",
       "4    Iris  LogisticRegression       saga        82.2359  [1000, 1000, 1000]   \n",
       "\n",
       "   Total Iterations  Score-Testing Data  Score-Training Data  \n",
       "0                 7            0.947368             0.964286  \n",
       "1                40            0.947368             0.946429  \n",
       "2                98            0.947368             0.946429  \n",
       "3              2640            0.947368             0.937500  \n",
       "4              3000            0.973684             0.937500  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_lr_iris_df = pd.DataFrame( model_results,\n",
    "          columns=['Dataset', 'Classifier', 'Solver', 'Fit Time (ms)', 'Iterations', 'Total Iterations', 'Score-Testing Data', 'Score-Training Data'])\n",
    "\n",
    "summary_lr_iris_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fit Time (ms)            49.146000\n",
       "Total Iterations       1157.000000\n",
       "Score-Testing Data        0.952632\n",
       "Score-Training Data       0.946429\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_lr_iris_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model: Decision Tree - Iris Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree: Function to Fit Model, Evaluate Performance - Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fit a model to training data, calculate predictions, and create a residuals chart\n",
    "def eval_decisiontree(a_model):\n",
    "    # Get the name of this model\n",
    "    m_name = str(a_model).split(\"(\",1)[0]\n",
    "    \n",
    "    # Get the maximum tree depth used with this model\n",
    "    m_max_tree_depth = str(a_model).split(\"max_depth=\")[1].split(\",\")[0].replace(\"'\",\"\").replace('\"','')\n",
    "\n",
    "    # Print a separator\n",
    "    print(\"*\"*80)\n",
    "    \n",
    "    # Print the model attributes\n",
    "    print(a_model)\n",
    "    \n",
    "    # Fit the data to the scaled data\n",
    "    m_fit_time = %timeit -n1 -r1 -o a_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions using both test and training data\n",
    "    y_predicted_test = a_model.predict(X_test)\n",
    "    y_predicted_train = a_model.predict(X_train)\n",
    "    \n",
    "    # Calculate Model performance: MSE and R2\n",
    "    m_score_test = a_model.score(X_test, y_test)\n",
    "    m_score_train = a_model.score(X_train, y_train)\n",
    "\n",
    "    print(f\"Performance - Model: {m_name}\\nScore - Test Data: {m_score_test}, Training Data: {m_score_train}\")\n",
    "#     print(f\"coef_: {a_model.coef_}, intercept_: {a_model.intercept_}, n_iter_: {a_model.n_iter_}, \")\n",
    "\n",
    "    # Generate a confusion matrix of the results for both test and training data\n",
    "    cm_test = confusion_matrix(y_test, a_model.predict(X_test))\n",
    "    print(\"\\nConfusion Matrix - Testing Data\")\n",
    "    print(cm_test)\n",
    "\n",
    "    cm_train = confusion_matrix(y_train, a_model.predict(X_train))\n",
    "    print(\"\\nConfusion Matrix - Training Data\")\n",
    "    print(cm_train)\n",
    "    \n",
    "    # Feature Importances\n",
    "    print(\"\\nFeature Importances\")\n",
    "    f_impt = [ { 'factor': iris.feature_names[x], 'importance': classifier.feature_importances_[x] } for x in np.arange(len(iris.feature_names)) ]\n",
    "    f_impt_df = pd.DataFrame(f_impt).sort_values(by='importance', ascending=False)\n",
    "    print(f_impt_df[['factor', 'importance']])\n",
    "    \n",
    "    # Display the Decision Tree using Graphviz\n",
    "#     dot_data = tree.export_graphviz(\n",
    "#                             a_model, out_file=None, \n",
    "#                             feature_names=iris.feature_names,  \n",
    "#                             class_names=iris.target_names,  \n",
    "#                             filled=True, rounded=True, special_characters=True)  \n",
    "\n",
    "#     graph = graphviz.Source(dot_data)  \n",
    "#     graph\n",
    "    \n",
    "    a_result = {\n",
    "        'model': m_name,\n",
    "        'max_depth': m_max_tree_depth,\n",
    "        'fit_time': m_fit_time.average,\n",
    "        'score_test': m_score_test,\n",
    "        'score_train': m_score_train\n",
    "    }\n",
    "    \n",
    "    return a_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fit a model to training data, calculate predictions, and create a residuals chart\n",
    "def eval_decisiontree_scaled(a_model):\n",
    "    # Get the name of this model\n",
    "    m_name = str(a_model).split(\"(\",1)[0]\n",
    "    \n",
    "    # Get the maximum tree depth used with this model\n",
    "    m_max_tree_depth = str(a_model).split(\"max_depth=\")[1].split(\",\")[0].replace(\"'\",\"\").replace('\"','')\n",
    "\n",
    "    # Print a separator\n",
    "    print(\"*\"*80)\n",
    "    \n",
    "    # Print the model attributes\n",
    "    print(a_model)\n",
    "    \n",
    "    # Fit the data to the scaled data\n",
    "    m_fit_time = %timeit -n1 -r1 -o a_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Calculate Model performance: MSE and R2\n",
    "    m_score_test = a_model.score(X_test_scaled, y_test)\n",
    "    m_score_train = a_model.score(X_train_scaled, y_train)\n",
    "\n",
    "    print(f\"Performance - Model: {m_name}\\nScore - Test Data: {m_score_test}, Training Data: {m_score_train}\")\n",
    "#     print(f\"coef_: {a_model.coef_}, intercept_: {a_model.intercept_}, n_iter_: {a_model.n_iter_}, \")\n",
    "\n",
    "    # Make predictions using both test and training data\n",
    "    y_predicted_test = a_model.predict(X_test_scaled)\n",
    "    y_predicted_train = a_model.predict(X_train_scaled)\n",
    "    \n",
    "    # Generate a confusion matrix of the results for both test and training data\n",
    "    cm_test = confusion_matrix(y_test, a_model.predict(X_test_scaled))\n",
    "    print(\"\\nConfusion Matrix - Testing Data\")\n",
    "    print(cm_test)\n",
    "\n",
    "    cm_train = confusion_matrix(y_train, a_model.predict(X_train_scaled))\n",
    "    print(\"\\nConfusion Matrix - Training Data\")\n",
    "    print(cm_train)\n",
    "    \n",
    "    # Feature Importances\n",
    "    print(\"\\nFeature Importances\")\n",
    "    f_impt = [ { 'factor': iris.feature_names[x], 'importance': classifier.feature_importances_[x] } for x in np.arange(len(iris.feature_names)) ]\n",
    "    f_impt_df = pd.DataFrame(f_impt).sort_values(by='importance', ascending=False)\n",
    "    print(f_impt_df[['factor', 'importance']])\n",
    "    \n",
    "    # Display the Decision Tree using Graphviz\n",
    "#     dot_data = tree.export_graphviz(\n",
    "#                             a_model, out_file=None, \n",
    "#                             feature_names=iris.feature_names,  \n",
    "#                             class_names=iris.target_names,  \n",
    "#                             filled=True, rounded=True, special_characters=True)  \n",
    "\n",
    "#     graph = graphviz.Source(dot_data)  \n",
    "#     graph\n",
    "    \n",
    "    a_result = {\n",
    "        'model': m_name,\n",
    "        'max_depth': m_max_tree_depth,\n",
    "        'fit_time': m_fit_time.average,\n",
    "        'score_test': m_score_test,\n",
    "        'score_train': m_score_train\n",
    "    }\n",
    "    \n",
    "    return a_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree: Iterate Models Parameter - Max Tree Depth - Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "504 µs ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "Performance - Model: DecisionTreeClassifier\n",
      "Score - Test Data: 0.9736842105263158, Training Data: 1.0\n",
      "\n",
      "Confusion Matrix - Testing Data\n",
      "[[12  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  1 12]]\n",
      "\n",
      "Confusion Matrix - Training Data\n",
      "[[38  0  0]\n",
      " [ 0 37  0]\n",
      " [ 0  0 37]]\n",
      "\n",
      "Feature Importances\n",
      "              factor  importance\n",
      "2  petal length (cm)    0.908006\n",
      "3   petal width (cm)    0.056277\n",
      "0  sepal length (cm)    0.035717\n",
      "1   sepal width (cm)    0.000000\n",
      "\n",
      "********************************************************************************\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=16,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "398 µs ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "Performance - Model: DecisionTreeClassifier\n",
      "Score - Test Data: 0.9736842105263158, Training Data: 1.0\n",
      "\n",
      "Confusion Matrix - Testing Data\n",
      "[[12  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  1 12]]\n",
      "\n",
      "Confusion Matrix - Training Data\n",
      "[[38  0  0]\n",
      " [ 0 37  0]\n",
      " [ 0  0 37]]\n",
      "\n",
      "Feature Importances\n",
      "              factor  importance\n",
      "3   petal width (cm)    0.560702\n",
      "2  petal length (cm)    0.403581\n",
      "0  sepal length (cm)    0.035717\n",
      "1   sepal width (cm)    0.000000\n",
      "\n",
      "********************************************************************************\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=8,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "424 µs ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "Performance - Model: DecisionTreeClassifier\n",
      "Score - Test Data: 0.9473684210526315, Training Data: 1.0\n",
      "\n",
      "Confusion Matrix - Testing Data\n",
      "[[12  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  2 11]]\n",
      "\n",
      "Confusion Matrix - Training Data\n",
      "[[38  0  0]\n",
      " [ 0 37  0]\n",
      " [ 0  0 37]]\n",
      "\n",
      "Feature Importances\n",
      "              factor  importance\n",
      "2  petal length (cm)    0.917723\n",
      "3   petal width (cm)    0.074136\n",
      "0  sepal length (cm)    0.008141\n",
      "1   sepal width (cm)    0.000000\n",
      "\n",
      "********************************************************************************\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "382 µs ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "Performance - Model: DecisionTreeClassifier\n",
      "Score - Test Data: 0.9736842105263158, Training Data: 0.9732142857142857\n",
      "\n",
      "Confusion Matrix - Testing Data\n",
      "[[12  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  1 12]]\n",
      "\n",
      "Confusion Matrix - Training Data\n",
      "[[38  0  0]\n",
      " [ 0 34  3]\n",
      " [ 0  0 37]]\n",
      "\n",
      "Feature Importances\n",
      "              factor  importance\n",
      "2  petal length (cm)    0.959407\n",
      "3   petal width (cm)    0.040593\n",
      "0  sepal length (cm)    0.000000\n",
      "1   sepal width (cm)    0.000000\n",
      "\n",
      "********************************************************************************\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "377 µs ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "Performance - Model: DecisionTreeClassifier\n",
      "Score - Test Data: 0.9473684210526315, Training Data: 0.9553571428571429\n",
      "\n",
      "Confusion Matrix - Testing Data\n",
      "[[12  0  0]\n",
      " [ 0 12  1]\n",
      " [ 0  1 12]]\n",
      "\n",
      "Confusion Matrix - Training Data\n",
      "[[38  0  0]\n",
      " [ 0 32  5]\n",
      " [ 0  0 37]]\n",
      "\n",
      "Feature Importances\n",
      "              factor  importance\n",
      "3   petal width (cm)    0.571906\n",
      "2  petal length (cm)    0.428094\n",
      "0  sepal length (cm)    0.000000\n",
      "1   sepal width (cm)    0.000000\n",
      "\n",
      "********************************************************************************\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "414 µs ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "Performance - Model: DecisionTreeClassifier\n",
      "Score - Test Data: 0.6578947368421053, Training Data: 0.6696428571428571\n",
      "\n",
      "Confusion Matrix - Testing Data\n",
      "[[12  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0 13  0]]\n",
      "\n",
      "Confusion Matrix - Training Data\n",
      "[[38  0  0]\n",
      " [ 0 37  0]\n",
      " [ 0 37  0]]\n",
      "\n",
      "Feature Importances\n",
      "              factor  importance\n",
      "3   petal width (cm)         1.0\n",
      "0  sepal length (cm)         0.0\n",
      "1   sepal width (cm)         0.0\n",
      "2  petal length (cm)         0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize list of dictionary of results for summary in a dataframe later\n",
    "model_results = []\n",
    "\n",
    "# List of tree max depth values over which to iterate\n",
    "max_depth_list = [ None, 16, 8, 4, 2, 1 ]\n",
    "\n",
    "# Generate classifer and an associated performance report for each\n",
    "for md in max_depth_list:\n",
    "    # Create a classifier model\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=md)\n",
    "    \n",
    "    # Evaluate the classifer performance, create a plot of \n",
    "#     r = eval_decisiontree(classifier)\n",
    "    r = eval_decisiontree_scaled(classifier)\n",
    "    model_results.append( {\n",
    "        'Dataset': 'Iris',\n",
    "        'Classifier': r['model'],\n",
    "        'Max Tree Depth': r['max_depth'],\n",
    "        'Fit Time (ms)': 1000.0*r['fit_time'],\n",
    "        'Score-Testing Data': r['score_test'],\n",
    "        'Score-Training Data': r['score_train'] } )\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree - Scaled: Summary - Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Max Tree Depth</th>\n",
       "      <th>Fit Time (ms)</th>\n",
       "      <th>Score-Testing Data</th>\n",
       "      <th>Score-Training Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5039</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iris</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>16</td>\n",
       "      <td>0.3984</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iris</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>8</td>\n",
       "      <td>0.4242</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iris</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>4</td>\n",
       "      <td>0.3816</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.973214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iris</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3774</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.955357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Iris</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4141</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.669643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset              Classifier Max Tree Depth  Fit Time (ms)  \\\n",
       "0    Iris  DecisionTreeClassifier           None         0.5039   \n",
       "1    Iris  DecisionTreeClassifier             16         0.3984   \n",
       "2    Iris  DecisionTreeClassifier              8         0.4242   \n",
       "3    Iris  DecisionTreeClassifier              4         0.3816   \n",
       "4    Iris  DecisionTreeClassifier              2         0.3774   \n",
       "5    Iris  DecisionTreeClassifier              1         0.4141   \n",
       "\n",
       "   Score-Testing Data  Score-Training Data  \n",
       "0            0.973684             1.000000  \n",
       "1            0.973684             1.000000  \n",
       "2            0.947368             1.000000  \n",
       "3            0.973684             0.973214  \n",
       "4            0.947368             0.955357  \n",
       "5            0.657895             0.669643  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_dt_iris_df = pd.DataFrame( model_results,\n",
    "          columns=['Dataset', 'Classifier', 'Max Tree Depth', 'Fit Time (ms)', 'Score-Testing Data', 'Score-Training Data'])\n",
    "summary_dt_iris_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fit Time (ms)          0.416600\n",
       "Score-Testing Data     0.912281\n",
       "Score-Training Data    0.933036\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_dt_iris_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voice Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.064241</td>\n",
       "      <td>0.032027</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.090193</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>12.863462</td>\n",
       "      <td>274.402906</td>\n",
       "      <td>0.893369</td>\n",
       "      <td>0.491918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.067310</td>\n",
       "      <td>0.040229</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>0.092666</td>\n",
       "      <td>0.073252</td>\n",
       "      <td>22.423285</td>\n",
       "      <td>634.613855</td>\n",
       "      <td>0.892193</td>\n",
       "      <td>0.513724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.107937</td>\n",
       "      <td>0.015826</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.083829</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.131908</td>\n",
       "      <td>0.123207</td>\n",
       "      <td>30.757155</td>\n",
       "      <td>1024.927705</td>\n",
       "      <td>0.846389</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.098706</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.072111</td>\n",
       "      <td>0.158011</td>\n",
       "      <td>0.096582</td>\n",
       "      <td>0.207955</td>\n",
       "      <td>0.111374</td>\n",
       "      <td>1.232831</td>\n",
       "      <td>4.177296</td>\n",
       "      <td>0.963322</td>\n",
       "      <td>0.727232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.088965</td>\n",
       "      <td>0.017798</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.201497</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.247119</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.079146</td>\n",
       "      <td>0.124656</td>\n",
       "      <td>0.078720</td>\n",
       "      <td>0.206045</td>\n",
       "      <td>0.127325</td>\n",
       "      <td>1.101174</td>\n",
       "      <td>4.333713</td>\n",
       "      <td>0.971955</td>\n",
       "      <td>0.783568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.106398</td>\n",
       "      <td>0.016931</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.712812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.484375</td>\n",
       "      <td>5.476562</td>\n",
       "      <td>0.208274</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
       "0  0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
       "1  0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
       "2  0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
       "3  0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
       "4  0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
       "\n",
       "          kurt    sp.ent       sfm  ...    centroid   meanfun    minfun  \\\n",
       "0   274.402906  0.893369  0.491918  ...    0.059781  0.084279  0.015702   \n",
       "1   634.613855  0.892193  0.513724  ...    0.066009  0.107937  0.015826   \n",
       "2  1024.927705  0.846389  0.478905  ...    0.077316  0.098706  0.015656   \n",
       "3     4.177296  0.963322  0.727232  ...    0.151228  0.088965  0.017798   \n",
       "4     4.333713  0.971955  0.783568  ...    0.135120  0.106398  0.016931   \n",
       "\n",
       "     maxfun   meandom    mindom    maxdom   dfrange   modindx  label  \n",
       "0  0.275862  0.007812  0.007812  0.007812  0.000000  0.000000   male  \n",
       "1  0.250000  0.009014  0.007812  0.054688  0.046875  0.052632   male  \n",
       "2  0.271186  0.007990  0.007812  0.015625  0.007812  0.046512   male  \n",
       "3  0.250000  0.201497  0.007812  0.562500  0.554688  0.247119   male  \n",
       "4  0.266667  0.712812  0.007812  5.484375  5.476562  0.208274   male  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Import Data and Pre-Process: Voice Dataset\n",
    "voice = pd.read_csv('resources/voice.csv')\n",
    "voice.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check datatypes to ensure numerical values are floats vs. objects -- CONFIRMED\n",
    "# voice.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3168, 20) (3168,)\n"
     ]
    }
   ],
   "source": [
    "# Assign X (data) and y (target)\n",
    "X = voice.drop(\"label\", axis=1)\n",
    "y = voice[\"label\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the output strings using a Categorical Binarizer\n",
    "label_encoder = LabelBinarizer()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data using train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, random_state=1, stratify=y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the outputs to provide a N by 1 vector (vs. array of size N)\n",
    "# y_train = y_train.reshape(-1,1)\n",
    "# y_test = y_test.reshape(-1,1)\n",
    "# print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dadja\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# Use the training data to create a scaler to standard normal distributions for each numerical feature and output\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "y_scaler = StandardScaler().fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dadja\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\dadja\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# Scale the training and test data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "y_train_scaled = y_scaler.transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model: Logistic Regression - Voice Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression: Function to Fit Model, Evaluate Performance - Voice Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fit a model to training data and evaluate classification performance\n",
    "def eval_logisticregression2(a_model):\n",
    "    # Get the name of this model\n",
    "    m_name = str(a_model).split(\"(\",1)[0]\n",
    "    \n",
    "    # Get the solver used with this model\n",
    "    m_solver = str(a_model).split(\"solver=\")[1].split(\",\")[0].replace(\"'\",\"\").replace('\"','')\n",
    "    \n",
    "    # Print a separator\n",
    "    print(\"*\"*80)\n",
    "    \n",
    "    # Print the model attributes\n",
    "    print(a_model)\n",
    "    \n",
    "    # Fit the data to the scaled data\n",
    "    m_fit_time = %timeit -n1 -r1 -o a_model.fit(X_train, y_train)\n",
    "\n",
    "#     # Flag points that were classified incorrectly\n",
    "#     y_predicted_test_errors = y_test - y_predicted_test\n",
    "#     y_predicted_train_errors = y_train - y_predicted_train\n",
    "\n",
    "    # Calculate Model performance: MSE and R2\n",
    "    m_score_test = a_model.score(X_test, y_test)\n",
    "    m_score_train = a_model.score(X_train, y_train)\n",
    "\n",
    "    print(f\"Performance - Model: {m_name}\\nScore - Test Data: {m_score_test}, Training Data: {m_score_train}\")\n",
    "    print(f\"coef_: {a_model.coef_}, intercept_: {a_model.intercept_}, n_iter_: {a_model.n_iter_}, \")\n",
    "\n",
    "    # Make predictions using both test and training data\n",
    "    y_predicted_test = a_model.predict(X_test)\n",
    "    y_predicted_train = a_model.predict(X_train)\n",
    "    \n",
    "    # Generate a confusion matrix of the results for both test and training data\n",
    "    cm_test = confusion_matrix(y_test, y_predicted_test)\n",
    "    cm_test_df = pd.DataFrame(cm_test, columns = [\"Female (Predicted)\", \"Male (Predicted)\"], index = [\"Female (Actual)\", \"Male (Actual)\"] )\n",
    "    print(\"Confusion Matrix - Testing Data\")\n",
    "    print(cm_test_df)\n",
    "\n",
    "    print(\"\")\n",
    "\n",
    "    cm_train = confusion_matrix(y_train, y_predicted_train)\n",
    "    cm_train_df = pd.DataFrame(cm_train, columns = [\"Female (Predicted)\", \"Male (Predicted)\"], index = [\"Female (Actual)\", \"Male (Actual)\"] )\n",
    "    print(\"Confusion Matrix - Training Data\")\n",
    "    print(cm_train_df)\n",
    "    \n",
    "#     # Plot the training and test data, with prediction errors highlighted in different color\n",
    "\n",
    "#     # Generate a plot\n",
    "#     plt.scatter(X_test[:,0], X_test[:,1], c=y_predicted_test_errors)\n",
    "#     plt.scatter(X_train[:,0], X_train[:,1], c=y_predicted_train_errors)\n",
    "    \n",
    "#     # plt.legend()\n",
    "\n",
    "#     plt.title(f\"Classification Results - Model: {m_name} / {m_solver}\")\n",
    "#     plt.show()\n",
    "\n",
    "    a_result = {\n",
    "        'model': m_name,\n",
    "        'solver': m_solver,\n",
    "        'fit_time': m_fit_time.average,\n",
    "        'n_iter': a_model.n_iter_,\n",
    "        'score_test': m_score_test,\n",
    "        'score_train': m_score_train\n",
    "    }\n",
    "    \n",
    "    return a_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fit a model to training data and evaluate classification performance\n",
    "def eval_logisticregression2_scaled(a_model):\n",
    "    # Get the name of this model\n",
    "    m_name = str(a_model).split(\"(\",1)[0]\n",
    "    \n",
    "    # Get the solver used with this model\n",
    "    m_solver = str(a_model).split(\"solver=\")[1].split(\",\")[0].replace(\"'\",\"\").replace('\"','')\n",
    "    \n",
    "    # Print a separator\n",
    "    print(\"*\"*80)\n",
    "    \n",
    "    # Print the model attributes\n",
    "    print(a_model)\n",
    "    \n",
    "    # Fit the data to the scaled data\n",
    "    m_fit_time = %timeit -n1 -r1 -o a_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "#     # Flag points that were classified incorrectly\n",
    "#     y_predicted_test_errors = y_test - y_predicted_test\n",
    "#     y_predicted_train_errors = y_train - y_predicted_train\n",
    "\n",
    "    # Calculate Model performance: MSE and R2\n",
    "    m_score_test = a_model.score(X_test_scaled, y_test)\n",
    "    m_score_train = a_model.score(X_train_scaled, y_train)\n",
    "\n",
    "    print(f\"Performance - Model: {m_name}\\nScore - Test Data: {m_score_test}, Training Data: {m_score_train}\")\n",
    "    print(f\"coef_: {a_model.coef_}, intercept_: {a_model.intercept_}, n_iter_: {a_model.n_iter_}, \")\n",
    "\n",
    "    # Make predictions using both test and training data\n",
    "    y_predicted_test = a_model.predict(X_test_scaled)\n",
    "    y_predicted_train = a_model.predict(X_train_scaled)\n",
    "    \n",
    "    # Generate a confusion matrix of the results for both test and training data\n",
    "    cm_test = confusion_matrix(y_test, y_predicted_test)\n",
    "    cm_test_df = pd.DataFrame(cm_test, columns = [\"Female (Predicted)\", \"Male (Predicted)\"], index = [\"Female (Actual)\", \"Male (Actual)\"] )\n",
    "    print(\"Confusion Matrix - Testing Data\")\n",
    "    print(cm_test_df)\n",
    "\n",
    "    print(\"\")\n",
    "\n",
    "    cm_train = confusion_matrix(y_train, y_predicted_train)\n",
    "    cm_train_df = pd.DataFrame(cm_train, columns = [\"Female (Predicted)\", \"Male (Predicted)\"], index = [\"Female (Actual)\", \"Male (Actual)\"] )\n",
    "    print(\"Confusion Matrix - Training Data\")\n",
    "    print(cm_train_df)\n",
    "    \n",
    "#     # Plot the training and test data, with prediction errors highlighted in different color\n",
    "\n",
    "#     # Generate a plot\n",
    "#     plt.scatter(X_test[:,0], X_test[:,1], c=y_predicted_test_errors)\n",
    "#     plt.scatter(X_train[:,0], X_train[:,1], c=y_predicted_train_errors)\n",
    "    \n",
    "#     # plt.legend()\n",
    "\n",
    "#     plt.title(f\"Classification Results - Model: {m_name} / {m_solver}\")\n",
    "#     plt.show()\n",
    "\n",
    "    a_result = {\n",
    "        'model': m_name,\n",
    "        'solver': m_solver,\n",
    "        'fit_time': m_fit_time.average,\n",
    "        'n_iter': a_model.n_iter_,\n",
    "        'score_test': m_score_test,\n",
    "        'score_train': m_score_train\n",
    "    }\n",
    "    \n",
    "    return a_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression: Iterate Model Parameter - Solver - Voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=1000, multi_class='warn', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "12.7 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dadja\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dadja\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dadja\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance - Model: LogisticRegression\n",
      "Score - Test Data: 0.9772727272727273, Training Data: 0.9730639730639731\n",
      "coef_: [[-0.08280714  0.10015708 -0.11984643 -0.82508817  0.59495457  1.2723231\n",
      "  -0.06696374 -0.38796226  1.35233418 -1.44620188  0.18825553 -0.08280714\n",
      "  -4.69788893  0.57718602  0.03316222 -0.03341153 -0.06294669  0.03191723\n",
      "   0.03305505 -0.25128625]], intercept_: [-0.79833416], n_iter_: [7], \n",
      "Confusion Matrix - Testing Data\n",
      "                 Female (Predicted)  Male (Predicted)\n",
      "Female (Actual)                 387                 9\n",
      "Male (Actual)                     9               387\n",
      "\n",
      "Confusion Matrix - Training Data\n",
      "                 Female (Predicted)  Male (Predicted)\n",
      "Female (Actual)                1149                39\n",
      "Male (Actual)                    25              1163\n",
      "\n",
      "********************************************************************************\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=1000, multi_class='warn', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "53.7 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "Performance - Model: LogisticRegression\n",
      "Score - Test Data: 0.9772727272727273, Training Data: 0.9722222222222222\n",
      "coef_: [[-0.08327234  0.11763806 -0.12261208 -0.82369322  0.59460349  1.27053351\n",
      "  -0.06613437 -0.38593905  1.37795427 -1.46940673  0.1899751  -0.08327234\n",
      "  -4.70607677  0.57679073  0.03907995 -0.02821909 -0.06326534  0.03086727\n",
      "   0.03201042 -0.25215631]], intercept_: [-0.82108017], n_iter_: [14], \n",
      "Confusion Matrix - Testing Data\n",
      "                 Female (Predicted)  Male (Predicted)\n",
      "Female (Actual)                 387                 9\n",
      "Male (Actual)                     9               387\n",
      "\n",
      "Confusion Matrix - Training Data\n",
      "                 Female (Predicted)  Male (Predicted)\n",
      "Female (Actual)                1149                39\n",
      "Male (Actual)                    27              1161\n",
      "\n",
      "********************************************************************************\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=1000, multi_class='warn', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "22.7 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "Performance - Model: LogisticRegression\n",
      "Score - Test Data: 0.9772727272727273, Training Data: 0.9722222222222222\n",
      "coef_: [[-0.08293582  0.1175984  -0.12277413 -0.82392095  0.59436471  1.27066221\n",
      "  -0.06610554 -0.38590918  1.37815391 -1.4695002   0.18994281 -0.08293582\n",
      "  -4.70589758  0.57676871  0.03901082 -0.02832371 -0.06324287  0.03090301\n",
      "   0.03204577 -0.25217618]], intercept_: [-0.82105256], n_iter_: [49], \n",
      "Confusion Matrix - Testing Data\n",
      "                 Female (Predicted)  Male (Predicted)\n",
      "Female (Actual)                 387                 9\n",
      "Male (Actual)                     9               387\n",
      "\n",
      "Confusion Matrix - Training Data\n",
      "                 Female (Predicted)  Male (Predicted)\n",
      "Female (Actual)                1149                39\n",
      "Male (Actual)                    27              1161\n",
      "\n",
      "********************************************************************************\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=1000, multi_class='warn', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dadja\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dadja\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "Performance - Model: LogisticRegression\n",
      "Score - Test Data: 0.9772727272727273, Training Data: 0.9722222222222222\n",
      "coef_: [[-0.07979809  0.11976034 -0.12445325 -0.82495238  0.59227046  1.27068594\n",
      "  -0.07739732 -0.37648248  1.37374094 -1.46662275  0.18924173 -0.07979809\n",
      "  -4.70597499  0.57646076  0.03928296 -0.0285965  -0.06297177  0.03085414\n",
      "   0.03199204 -0.25207668]], intercept_: [-0.82075325], n_iter_: [90], \n",
      "Confusion Matrix - Testing Data\n",
      "                 Female (Predicted)  Male (Predicted)\n",
      "Female (Actual)                 387                 9\n",
      "Male (Actual)                     9               387\n",
      "\n",
      "Confusion Matrix - Training Data\n",
      "                 Female (Predicted)  Male (Predicted)\n",
      "Female (Actual)                1149                39\n",
      "Male (Actual)                    27              1161\n",
      "\n",
      "********************************************************************************\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=1000, multi_class='warn', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='saga', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "168 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "Performance - Model: LogisticRegression\n",
      "Score - Test Data: 0.9772727272727273, Training Data: 0.9722222222222222\n",
      "coef_: [[-0.0812585   0.11829095 -0.12327214 -0.82425966  0.59342212  1.27052931\n",
      "  -0.08977184 -0.36638071  1.36818409 -1.46263819  0.18844217 -0.0812585\n",
      "  -4.70604871  0.57600105  0.039402   -0.02894382 -0.06265837  0.03080236\n",
      "   0.03193463 -0.25211075]], intercept_: [-0.81995531], n_iter_: [157], \n",
      "Confusion Matrix - Testing Data\n",
      "                 Female (Predicted)  Male (Predicted)\n",
      "Female (Actual)                 387                 9\n",
      "Male (Actual)                     9               387\n",
      "\n",
      "Confusion Matrix - Training Data\n",
      "                 Female (Predicted)  Male (Predicted)\n",
      "Female (Actual)                1149                39\n",
      "Male (Actual)                    27              1161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize list of dictionary of results for summary in a dataframe later\n",
    "model_results = []\n",
    "\n",
    "# List of Solvers to use with LogisticRegression model\n",
    "solver_list = \"liblinear\", \"newton-cg\", \"lbfgs\", \"sag\", \"saga\"\n",
    "\n",
    "# Generate classifer and an associated performance report for each\n",
    "for s in solver_list:\n",
    "    # Create a classifier model\n",
    "    classifier = LogisticRegression(solver=s, n_jobs=1, max_iter=1000)\n",
    "    \n",
    "    # Evaluate the classifer performance, create a plot of \n",
    "#     r = eval_logisticregression2(classifier)\n",
    "    r = eval_logisticregression2_scaled(classifier)\n",
    "    model_results.append( {\n",
    "        'Dataset': 'Voice',\n",
    "        'Classifier': r['model'],\n",
    "        'Solver': r['solver'],\n",
    "        'Fit Time (ms)': 1000.0*r['fit_time'],\n",
    "        'Iterations': r['n_iter'],\n",
    "        'Total Iterations': sum(r['n_iter']),\n",
    "        'Score-Testing Data': r['score_test'],\n",
    "        'Score-Training Data': r['score_train'] } )\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression - Scaled: Summary - Voice Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Solver</th>\n",
       "      <th>Fit Time (ms)</th>\n",
       "      <th>Iterations</th>\n",
       "      <th>Total Iterations</th>\n",
       "      <th>Score-Testing Data</th>\n",
       "      <th>Score-Training Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Voice</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>12.7224</td>\n",
       "      <td>[7]</td>\n",
       "      <td>7</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.973064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Voice</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>53.6979</td>\n",
       "      <td>[14]</td>\n",
       "      <td>14</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.972222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voice</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>22.6674</td>\n",
       "      <td>[49]</td>\n",
       "      <td>49</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.972222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voice</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>sag</td>\n",
       "      <td>116.2488</td>\n",
       "      <td>[90]</td>\n",
       "      <td>90</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.972222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Voice</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>saga</td>\n",
       "      <td>167.9294</td>\n",
       "      <td>[157]</td>\n",
       "      <td>157</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.972222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset          Classifier     Solver  Fit Time (ms) Iterations  \\\n",
       "0   Voice  LogisticRegression  liblinear        12.7224        [7]   \n",
       "1   Voice  LogisticRegression  newton-cg        53.6979       [14]   \n",
       "2   Voice  LogisticRegression      lbfgs        22.6674       [49]   \n",
       "3   Voice  LogisticRegression        sag       116.2488       [90]   \n",
       "4   Voice  LogisticRegression       saga       167.9294      [157]   \n",
       "\n",
       "   Total Iterations  Score-Testing Data  Score-Training Data  \n",
       "0                 7            0.977273             0.973064  \n",
       "1                14            0.977273             0.972222  \n",
       "2                49            0.977273             0.972222  \n",
       "3                90            0.977273             0.972222  \n",
       "4               157            0.977273             0.972222  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_lr_voice_df = pd.DataFrame( model_results,\n",
    "          columns=['Dataset', 'Classifier', 'Solver', 'Fit Time (ms)', 'Iterations', 'Total Iterations', 'Score-Testing Data', 'Score-Training Data'])\n",
    "summary_lr_voice_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fit Time (ms)          74.653180\n",
       "Total Iterations       63.400000\n",
       "Score-Testing Data      0.977273\n",
       "Score-Training Data     0.972391\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_lr_voice_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model: Decision Tree - Voice Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree: Function to Fit Model, Evaluate Performance - Voice Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fit a model to training data, calculate predictions, and create a residuals chart\n",
    "def eval_decisiontree2(a_model):\n",
    "    # Get the name of this model\n",
    "    m_name = str(a_model).split(\"(\",1)[0]\n",
    "    \n",
    "    # Get the maximum tree depth used with this model\n",
    "    m_max_tree_depth = str(a_model).split(\"max_depth=\")[1].split(\",\")[0].replace(\"'\",\"\").replace('\"','')\n",
    "\n",
    "    # Print a separator\n",
    "    print(\"*\"*80)\n",
    "    \n",
    "    # Print the model attributes\n",
    "    print(a_model)\n",
    "    \n",
    "    # Fit the data to the scaled data\n",
    "    m_fit_time = %timeit -n1 -r1 -o a_model.fit(X_train, y_train)\n",
    "\n",
    "    # Calculate Model performance: MSE and R2\n",
    "    m_score_test = a_model.score(X_test, y_test)\n",
    "    m_score_train = a_model.score(X_train, y_train)\n",
    "\n",
    "    print(f\"Performance - Model: {m_name}\\nScore - Test Data: {m_score_test}, Training Data: {m_score_train}\")\n",
    "#     print(f\"coef_: {a_model.coef_}, intercept_: {a_model.intercept_}, n_iter_: {a_model.n_iter_}, \")\n",
    "\n",
    "#     # Generate a confusion matrix of the results for both test and training data\n",
    "#     cm_test = confusion_matrix(y_test, a_model.predict(X_test))\n",
    "#     print(\"\\nConfusion Matrix - Testing Data\")\n",
    "#     print(cm_test)\n",
    "\n",
    "#     cm_train = confusion_matrix(y_train, a_model.predict(X_train))\n",
    "#     print(\"\\nConfusion Matrix - Training Data\")\n",
    "#     print(cm_train)\n",
    "    \n",
    "    # Make predictions using both test and training data\n",
    "    y_predicted_test = a_model.predict(X_test)\n",
    "    y_predicted_train = a_model.predict(X_train)\n",
    "    \n",
    "    # Generate a confusion matrix of the results for both test and training data\n",
    "    cm_test = confusion_matrix(y_test, y_predicted_test)\n",
    "    cm_test_df = pd.DataFrame(cm_test, columns = [\"Female (Predicted)\", \"Male (Predicted)\"], index = [\"Female (Actual)\", \"Male (Actual)\"] )\n",
    "    print(\"Confusion Matrix - Testing Data\")\n",
    "    print(cm_test_df)\n",
    "\n",
    "    print(\"\")\n",
    "\n",
    "    cm_train = confusion_matrix(y_train, y_predicted_train)\n",
    "    cm_train_df = pd.DataFrame(cm_train, columns = [\"Female (Predicted)\", \"Male (Predicted)\"], index = [\"Female (Actual)\", \"Male (Actual)\"] )\n",
    "    print(\"Confusion Matrix - Training Data\")\n",
    "    print(cm_train_df)\n",
    "\n",
    "    # Feature Importances\n",
    "    print(\"\\nFeature Importances\")\n",
    "    f_impt = [ { 'factor': iris.feature_names[x], 'importance': classifier.feature_importances_[x] } for x in np.arange(len(iris.feature_names)) ]\n",
    "    f_impt_df = pd.DataFrame(f_impt).sort_values(by='importance', ascending=False)\n",
    "    print(f_impt_df[['factor', 'importance']])\n",
    "    \n",
    "    # Display the Decision Tree using Graphviz\n",
    "#     dot_data = tree.export_graphviz(\n",
    "#                             a_model, out_file=None, \n",
    "#                             feature_names=iris.feature_names,  \n",
    "#                             class_names=iris.target_names,  \n",
    "#                             filled=True, rounded=True, special_characters=True)  \n",
    "\n",
    "#     graph = graphviz.Source(dot_data)  \n",
    "#     graph\n",
    "    \n",
    "    a_result = {\n",
    "        'model': m_name,\n",
    "        'max_depth': m_max_tree_depth,\n",
    "        'fit_time': m_fit_time.average,\n",
    "        'score_test': m_score_test,\n",
    "        'score_train': m_score_train\n",
    "    }\n",
    "    \n",
    "    return a_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fit a model to training data, calculate predictions, and create a residuals chart\n",
    "def eval_decisiontree2_scaled(a_model):\n",
    "    # Get the name of this model\n",
    "    m_name = str(a_model).split(\"(\",1)[0]\n",
    "    \n",
    "    # Get the maximum tree depth used with this model\n",
    "    m_max_tree_depth = str(a_model).split(\"max_depth=\")[1].split(\",\")[0].replace(\"'\",\"\").replace('\"','')\n",
    "\n",
    "    # Print a separator\n",
    "    print(\"*\"*80)\n",
    "    \n",
    "    # Print the model attributes\n",
    "    print(a_model)\n",
    "    \n",
    "    # Fit the data to the scaled data\n",
    "    m_fit_time = %timeit -n1 -r1 -o a_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Calculate Model performance: MSE and R2\n",
    "    m_score_test = a_model.score(X_test_scaled, y_test)\n",
    "    m_score_train = a_model.score(X_train_scaled, y_train)\n",
    "\n",
    "    print(f\"Performance - Model: {m_name}\\nScore - Test Data: {m_score_test}, Training Data: {m_score_train}\")\n",
    "#     print(f\"coef_: {a_model.coef_}, intercept_: {a_model.intercept_}, n_iter_: {a_model.n_iter_}, \")\n",
    "\n",
    "#     # Generate a confusion matrix of the results for both test and training data\n",
    "#     cm_test = confusion_matrix(y_test, a_model.predict(X_test))\n",
    "#     print(\"\\nConfusion Matrix - Testing Data\")\n",
    "#     print(cm_test)\n",
    "\n",
    "#     cm_train = confusion_matrix(y_train, a_model.predict(X_train))\n",
    "#     print(\"\\nConfusion Matrix - Training Data\")\n",
    "#     print(cm_train)\n",
    "    \n",
    "    # Make predictions using both test and training data\n",
    "    y_predicted_test = a_model.predict(X_test_scaled)\n",
    "    y_predicted_train = a_model.predict(X_train_scaled)\n",
    "    \n",
    "    # Generate a confusion matrix of the results for both test and training data\n",
    "    cm_test = confusion_matrix(y_test, y_predicted_test)\n",
    "    cm_test_df = pd.DataFrame(cm_test, columns = [\"Female (Predicted)\", \"Male (Predicted)\"], index = [\"Female (Actual)\", \"Male (Actual)\"] )\n",
    "    print(\"Confusion Matrix - Testing Data\")\n",
    "    print(cm_test_df)\n",
    "\n",
    "    print(\"\")\n",
    "\n",
    "    cm_train = confusion_matrix(y_train, y_predicted_train)\n",
    "    cm_train_df = pd.DataFrame(cm_train, columns = [\"Female (Predicted)\", \"Male (Predicted)\"], index = [\"Female (Actual)\", \"Male (Actual)\"] )\n",
    "    print(\"Confusion Matrix - Training Data\")\n",
    "    print(cm_train_df)\n",
    "\n",
    "    # Feature Importances\n",
    "    print(\"\\nFeature Importances\")\n",
    "    f_impt = [ { 'factor': iris.feature_names[x], 'importance': classifier.feature_importances_[x] } for x in np.arange(len(iris.feature_names)) ]\n",
    "    f_impt_df = pd.DataFrame(f_impt).sort_values(by='importance', ascending=False)\n",
    "    print(f_impt_df[['factor', 'importance']])\n",
    "    \n",
    "    # Display the Decision Tree using Graphviz\n",
    "#     dot_data = tree.export_graphviz(\n",
    "#                             a_model, out_file=None, \n",
    "#                             feature_names=iris.feature_names,  \n",
    "#                             class_names=iris.target_names,  \n",
    "#                             filled=True, rounded=True, special_characters=True)  \n",
    "\n",
    "#     graph = graphviz.Source(dot_data)  \n",
    "#     graph\n",
    "    \n",
    "    a_result = {\n",
    "        'model': m_name,\n",
    "        'max_depth': m_max_tree_depth,\n",
    "        'fit_time': m_fit_time.average,\n",
    "        'score_test': m_score_test,\n",
    "        'score_train': m_score_train\n",
    "    }\n",
    "    \n",
    "    return a_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree: Iterate Models Parameter - Max Tree Depth - Voice Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "29.2 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "Performance - Model: DecisionTreeClassifier\n",
      "Score - Test Data: 0.9709595959595959, Training Data: 1.0\n",
      "\n",
      "Confusion Matrix - Testing Data\n",
      "[[388   8]\n",
      " [ 15 381]]\n",
      "\n",
      "Confusion Matrix - Training Data\n",
      "[[1188    0]\n",
      " [   0 1188]]\n",
      "\n",
      "Feature Importances\n",
      "              factor  importance\n",
      "1   sepal width (cm)    0.008655\n",
      "0  sepal length (cm)    0.004285\n",
      "3   petal width (cm)    0.001496\n",
      "2  petal length (cm)    0.000000\n",
      "\n",
      "********************************************************************************\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=16,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "21.2 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "Performance - Model: DecisionTreeClassifier\n",
      "Score - Test Data: 0.9684343434343434, Training Data: 1.0\n",
      "\n",
      "Confusion Matrix - Testing Data\n",
      "[[384  12]\n",
      " [ 13 383]]\n",
      "\n",
      "Confusion Matrix - Training Data\n",
      "[[1188    0]\n",
      " [   0 1188]]\n",
      "\n",
      "Feature Importances\n",
      "              factor  importance\n",
      "0  sepal length (cm)    0.006962\n",
      "1   sepal width (cm)    0.004716\n",
      "2  petal length (cm)    0.003032\n",
      "3   petal width (cm)    0.001443\n",
      "\n",
      "********************************************************************************\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=8,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "25.9 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "Performance - Model: DecisionTreeClassifier\n",
      "Score - Test Data: 0.9734848484848485, Training Data: 0.9983164983164983\n",
      "\n",
      "Confusion Matrix - Testing Data\n",
      "[[389   7]\n",
      " [ 14 382]]\n",
      "\n",
      "Confusion Matrix - Training Data\n",
      "[[1186    2]\n",
      " [   2 1186]]\n",
      "\n",
      "Feature Importances\n",
      "              factor  importance\n",
      "1   sepal width (cm)    0.004742\n",
      "3   petal width (cm)    0.004310\n",
      "0  sepal length (cm)    0.002908\n",
      "2  petal length (cm)    0.000000\n",
      "\n",
      "********************************************************************************\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "15.6 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "Performance - Model: DecisionTreeClassifier\n",
      "Score - Test Data: 0.976010101010101, Training Data: 0.9810606060606061\n",
      "\n",
      "Confusion Matrix - Testing Data\n",
      "[[390   6]\n",
      " [ 13 383]]\n",
      "\n",
      "Confusion Matrix - Training Data\n",
      "[[1176   12]\n",
      " [  33 1155]]\n",
      "\n",
      "Feature Importances\n",
      "              factor  importance\n",
      "0  sepal length (cm)    0.001741\n",
      "1   sepal width (cm)    0.000000\n",
      "2  petal length (cm)    0.000000\n",
      "3   petal width (cm)    0.000000\n",
      "\n",
      "********************************************************************************\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "8.31 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "Performance - Model: DecisionTreeClassifier\n",
      "Score - Test Data: 0.9633838383838383, Training Data: 0.9625420875420876\n",
      "\n",
      "Confusion Matrix - Testing Data\n",
      "[[388   8]\n",
      " [ 21 375]]\n",
      "\n",
      "Confusion Matrix - Training Data\n",
      "[[1160   28]\n",
      " [  61 1127]]\n",
      "\n",
      "Feature Importances\n",
      "              factor  importance\n",
      "0  sepal length (cm)         0.0\n",
      "1   sepal width (cm)         0.0\n",
      "2  petal length (cm)         0.0\n",
      "3   petal width (cm)         0.0\n",
      "\n",
      "********************************************************************************\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "4.56 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "Performance - Model: DecisionTreeClassifier\n",
      "Score - Test Data: 0.9558080808080808, Training Data: 0.9532828282828283\n",
      "\n",
      "Confusion Matrix - Testing Data\n",
      "[[374  22]\n",
      " [ 13 383]]\n",
      "\n",
      "Confusion Matrix - Training Data\n",
      "[[1118   70]\n",
      " [  41 1147]]\n",
      "\n",
      "Feature Importances\n",
      "              factor  importance\n",
      "0  sepal length (cm)         0.0\n",
      "1   sepal width (cm)         0.0\n",
      "2  petal length (cm)         0.0\n",
      "3   petal width (cm)         0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize list of dictionary of results for summary in a dataframe later\n",
    "model_results = []\n",
    "\n",
    "# List of tree max depth values over which to iterate\n",
    "max_depth_list = [ None, 16, 8, 4, 2, 1 ]\n",
    "\n",
    "# Generate classifer and an associated performance report for each\n",
    "for md in max_depth_list:\n",
    "    # Create a classifier model\n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=md)\n",
    "    \n",
    "    # Evaluate the classifer performance, create a plot of \n",
    "#     r = eval_decisiontree(classifier)\n",
    "    r = eval_decisiontree_scaled(classifier)\n",
    "    model_results.append( {\n",
    "        'Dataset': 'Voice',\n",
    "        'Classifier': r['model'],\n",
    "        'Max Tree Depth': r['max_depth'],\n",
    "        'Fit Time (ms)': 1000.0*r['fit_time'],\n",
    "        'Score-Testing Data': r['score_test'],\n",
    "        'Score-Training Data': r['score_train'] } )\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree - Scaled: Summary - Voice Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Max Tree Depth</th>\n",
       "      <th>Fit Time (ms)</th>\n",
       "      <th>Score-Testing Data</th>\n",
       "      <th>Score-Training Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Voice</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>None</td>\n",
       "      <td>29.2341</td>\n",
       "      <td>0.970960</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Voice</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>16</td>\n",
       "      <td>21.1731</td>\n",
       "      <td>0.968434</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voice</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>8</td>\n",
       "      <td>25.8690</td>\n",
       "      <td>0.973485</td>\n",
       "      <td>0.998316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voice</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>4</td>\n",
       "      <td>15.6431</td>\n",
       "      <td>0.976010</td>\n",
       "      <td>0.981061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Voice</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>2</td>\n",
       "      <td>8.3096</td>\n",
       "      <td>0.963384</td>\n",
       "      <td>0.962542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Voice</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5574</td>\n",
       "      <td>0.955808</td>\n",
       "      <td>0.953283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset              Classifier Max Tree Depth  Fit Time (ms)  \\\n",
       "0   Voice  DecisionTreeClassifier           None        29.2341   \n",
       "1   Voice  DecisionTreeClassifier             16        21.1731   \n",
       "2   Voice  DecisionTreeClassifier              8        25.8690   \n",
       "3   Voice  DecisionTreeClassifier              4        15.6431   \n",
       "4   Voice  DecisionTreeClassifier              2         8.3096   \n",
       "5   Voice  DecisionTreeClassifier              1         4.5574   \n",
       "\n",
       "   Score-Testing Data  Score-Training Data  \n",
       "0            0.970960             1.000000  \n",
       "1            0.968434             1.000000  \n",
       "2            0.973485             0.998316  \n",
       "3            0.976010             0.981061  \n",
       "4            0.963384             0.962542  \n",
       "5            0.955808             0.953283  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_dt_voice_df = pd.DataFrame( model_results,\n",
    "          columns=['Dataset', 'Classifier', 'Max Tree Depth', 'Fit Time (ms)', 'Score-Testing Data', 'Score-Training Data'])\n",
    "summary_dt_voice_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fit Time (ms)          17.464383\n",
       "Score-Testing Data      0.968013\n",
       "Score-Training Data     0.982534\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_dt_voice_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the summary results for each set of classification runs\n",
    "dt_iris_subset_df = summary_dt_iris_df[\n",
    "    ['Dataset', 'Classifier', 'Max Tree Depth',\n",
    "     'Fit Time (ms)', 'Score-Testing Data', 'Score-Training Data']]\n",
    "\n",
    "lr_iris_subset_df = summary_lr_iris_df[\n",
    "    ['Dataset', 'Classifier', 'Solver', 'Iterations', 'Total Iterations',\n",
    "     'Fit Time (ms)', 'Score-Testing Data', 'Score-Training Data']]\n",
    "\n",
    "dt_voice_subset_df = summary_dt_voice_df[\n",
    "    ['Dataset', 'Classifier', 'Max Tree Depth',\n",
    "     'Fit Time (ms)', 'Score-Testing Data', 'Score-Training Data']]\n",
    "\n",
    "lr_voice_subset_df = summary_lr_voice_df[\n",
    "    ['Dataset', 'Classifier', 'Solver', 'Iterations', 'Total Iterations',\n",
    "     'Fit Time (ms)', 'Score-Testing Data', 'Score-Training Data']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Solver</th>\n",
       "      <th>Iterations</th>\n",
       "      <th>Total Iterations</th>\n",
       "      <th>Max Tree Depth</th>\n",
       "      <th>Fit Time (ms)</th>\n",
       "      <th>Score-Testing Data</th>\n",
       "      <th>Score-Training Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5039</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iris</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>0.3984</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iris</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>0.4242</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iris</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0.3816</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.973214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iris</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3774</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.955357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Iris</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4141</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.669643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Iris</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>[7]</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.8474</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.964286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Iris</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>[12, 14, 14]</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.4624</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.946429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Iris</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>[32, 35, 31]</td>\n",
       "      <td>98.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.7461</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.946429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Iris</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>sag</td>\n",
       "      <td>[1000, 640, 1000]</td>\n",
       "      <td>2640.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.4382</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Iris</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>saga</td>\n",
       "      <td>[1000, 1000, 1000]</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.2359</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Voice</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>29.2341</td>\n",
       "      <td>0.970960</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Voice</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>21.1731</td>\n",
       "      <td>0.968434</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Voice</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>25.8690</td>\n",
       "      <td>0.973485</td>\n",
       "      <td>0.998316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Voice</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>15.6431</td>\n",
       "      <td>0.976010</td>\n",
       "      <td>0.981061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Voice</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>8.3096</td>\n",
       "      <td>0.963384</td>\n",
       "      <td>0.962542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Voice</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5574</td>\n",
       "      <td>0.955808</td>\n",
       "      <td>0.953283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Voice</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>[7]</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.7224</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.973064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Voice</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>[14]</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.6979</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.972222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Voice</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>[49]</td>\n",
       "      <td>49.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.6674</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.972222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Voice</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>sag</td>\n",
       "      <td>[90]</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>116.2488</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.972222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Voice</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>saga</td>\n",
       "      <td>[157]</td>\n",
       "      <td>157.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167.9294</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.972222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dataset              Classifier     Solver          Iterations  \\\n",
       "0     Iris  DecisionTreeClassifier        NaN                 NaN   \n",
       "1     Iris  DecisionTreeClassifier        NaN                 NaN   \n",
       "2     Iris  DecisionTreeClassifier        NaN                 NaN   \n",
       "3     Iris  DecisionTreeClassifier        NaN                 NaN   \n",
       "4     Iris  DecisionTreeClassifier        NaN                 NaN   \n",
       "5     Iris  DecisionTreeClassifier        NaN                 NaN   \n",
       "6     Iris      LogisticRegression  liblinear                 [7]   \n",
       "7     Iris      LogisticRegression  newton-cg        [12, 14, 14]   \n",
       "8     Iris      LogisticRegression      lbfgs        [32, 35, 31]   \n",
       "9     Iris      LogisticRegression        sag   [1000, 640, 1000]   \n",
       "10    Iris      LogisticRegression       saga  [1000, 1000, 1000]   \n",
       "11   Voice  DecisionTreeClassifier        NaN                 NaN   \n",
       "12   Voice  DecisionTreeClassifier        NaN                 NaN   \n",
       "13   Voice  DecisionTreeClassifier        NaN                 NaN   \n",
       "14   Voice  DecisionTreeClassifier        NaN                 NaN   \n",
       "15   Voice  DecisionTreeClassifier        NaN                 NaN   \n",
       "16   Voice  DecisionTreeClassifier        NaN                 NaN   \n",
       "17   Voice      LogisticRegression  liblinear                 [7]   \n",
       "18   Voice      LogisticRegression  newton-cg                [14]   \n",
       "19   Voice      LogisticRegression      lbfgs                [49]   \n",
       "20   Voice      LogisticRegression        sag                [90]   \n",
       "21   Voice      LogisticRegression       saga               [157]   \n",
       "\n",
       "    Total Iterations Max Tree Depth  Fit Time (ms)  Score-Testing Data  \\\n",
       "0                NaN           None         0.5039            0.973684   \n",
       "1                NaN             16         0.3984            0.973684   \n",
       "2                NaN              8         0.4242            0.947368   \n",
       "3                NaN              4         0.3816            0.973684   \n",
       "4                NaN              2         0.3774            0.947368   \n",
       "5                NaN              1         0.4141            0.657895   \n",
       "6                7.0            NaN        22.8474            0.947368   \n",
       "7               40.0            NaN        24.4624            0.947368   \n",
       "8               98.0            NaN        15.7461            0.947368   \n",
       "9             2640.0            NaN       100.4382            0.947368   \n",
       "10            3000.0            NaN        82.2359            0.973684   \n",
       "11               NaN           None        29.2341            0.970960   \n",
       "12               NaN             16        21.1731            0.968434   \n",
       "13               NaN              8        25.8690            0.973485   \n",
       "14               NaN              4        15.6431            0.976010   \n",
       "15               NaN              2         8.3096            0.963384   \n",
       "16               NaN              1         4.5574            0.955808   \n",
       "17               7.0            NaN        12.7224            0.977273   \n",
       "18              14.0            NaN        53.6979            0.977273   \n",
       "19              49.0            NaN        22.6674            0.977273   \n",
       "20              90.0            NaN       116.2488            0.977273   \n",
       "21             157.0            NaN       167.9294            0.977273   \n",
       "\n",
       "    Score-Training Data  \n",
       "0              1.000000  \n",
       "1              1.000000  \n",
       "2              1.000000  \n",
       "3              0.973214  \n",
       "4              0.955357  \n",
       "5              0.669643  \n",
       "6              0.964286  \n",
       "7              0.946429  \n",
       "8              0.946429  \n",
       "9              0.937500  \n",
       "10             0.937500  \n",
       "11             1.000000  \n",
       "12             1.000000  \n",
       "13             0.998316  \n",
       "14             0.981061  \n",
       "15             0.962542  \n",
       "16             0.953283  \n",
       "17             0.973064  \n",
       "18             0.972222  \n",
       "19             0.972222  \n",
       "20             0.972222  \n",
       "21             0.972222  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the results into an overall summary dataframe\n",
    "overall_df = pd.concat([dt_iris_subset_df, lr_iris_subset_df,\n",
    "                        dt_voice_subset_df, lr_voice_subset_df], sort=True).reset_index(drop=True)\n",
    "overall_df = overall_df[['Dataset', 'Classifier',\n",
    "                         'Solver', 'Iterations', 'Total Iterations',\n",
    "                         'Max Tree Depth', \n",
    "                         'Fit Time (ms)', 'Score-Testing Data', 'Score-Training Data' ]]\n",
    "overall_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Gather data needed for plots for each Dataset and Classifier\n",
    "def get_plot_data(a_x_col, a_y_col):\n",
    "    \n",
    "    # Sort the dataframe in ascending order by the column a_x_col\n",
    "    sorted_df = overall_df.sort_values(by=a_x_col, ascending=True)\n",
    "    \n",
    "    plt_list = []\n",
    "    plt_i = 0\n",
    "    for ds in sorted_df['Dataset'].unique():\n",
    "        for cls in sorted_df['Classifier'].unique():\n",
    "            \n",
    "            \n",
    "\n",
    "            x_val = list(sorted_df[a_x_col]\n",
    "                             [ (sorted_df['Dataset']==ds) & (sorted_df['Classifier']==cls) ])\n",
    "\n",
    "            y_val = list(sorted_df[a_y_col]\n",
    "                             [ (sorted_df['Dataset']==ds) & (sorted_df['Classifier']==cls) ])\n",
    "            \n",
    "            solver_val = list(sorted_df['Solver']\n",
    "                             [ (sorted_df['Dataset']==ds) & (sorted_df['Classifier']==cls) \n",
    "                                & sorted_df['Solver'].notnull() ])\n",
    "\n",
    "            tot_iter_val = list(sorted_df['Total Iterations']\n",
    "                             [ (sorted_df['Dataset']==ds) & (sorted_df['Classifier']==cls) \n",
    "                                & sorted_df['Total Iterations'].notnull() ])\n",
    "\n",
    "            max_depth_val = list(sorted_df['Max Tree Depth']\n",
    "                             [ (sorted_df['Dataset']==ds) & (sorted_df['Classifier']==cls) \n",
    "                                & sorted_df['Max Tree Depth'].notnull() ])\n",
    "\n",
    "            plt_info = {\n",
    "                'title': f\"Dataset {ds}/Classifer {cls}\",\n",
    "                'x_column': a_x_col,\n",
    "                'x': x_val,\n",
    "                'y_column': a_y_col,\n",
    "                'y': y_val,\n",
    "                'solver': solver_val,\n",
    "                'tot_iter': tot_iter_val,\n",
    "                'max_depth': max_depth_val\n",
    "            }\n",
    "\n",
    "            plt_list.append(plt_info)\n",
    "            plt_i += 1\n",
    "    return plt_list\n",
    "        \n",
    "# Columns to plot\n",
    "x_column = 'Fit Time (ms)'\n",
    "y_column = 'Score-Testing Data'\n",
    "\n",
    "p_info_list = get_plot_data(x_column, y_column)\n",
    "# pprint(p_info_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Setup the axes and plots\n",
    "def create_plot(a_ax, a_plt_info):\n",
    "    \n",
    "    # Set the title\n",
    "    a_ax.set_title(a_plt_info['title'])\n",
    "    \n",
    "    # Set the y-axis range to (0,1), normal range for model scores\n",
    "    a_ax.set_ylabel(a_plt_info['y_column'])\n",
    "    a_ax.set_ylim(0,1.1)\n",
    "    \n",
    "    # Set the x-axis minimum to 0 and maximum to the max Fit Time overall\n",
    "    a_ax.set_xlabel(a_plt_info['x_column'])\n",
    "    a_ax.set_xlim(0, 1.1*max(a_plt_info['x']))\n",
    "    \n",
    "    # Plot the data\n",
    "    a_ax.scatter( a_plt_info['x'], a_plt_info['y'], c=\"b\" )\n",
    "    \n",
    "    # Plot a linear trend line\n",
    "    z = np.polyfit(a_plt_info['x'], a_plt_info['y'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    a_ax.plot( a_plt_info['x'], p(a_plt_info['x']), c=\"r\", linestyle='-', linewidth=0.5 )\n",
    "    \n",
    "    # Add grid lines\n",
    "    a_ax.grid(c='k', linestyle='-', linewidth=0.2)\n",
    "    \n",
    "    # Add text to the first datapoint\n",
    "    first_point_text = f\"({a_plt_info['x'][0]:0.2f}, {a_plt_info['y'][0]:0.2f})\"\n",
    "    \n",
    "    try:\n",
    "        first_point_text += f\"\\nSolver: {a_plt_info['solver'][0]}\"\n",
    "        first_point_text += f\"\\nTotal Iterations: {a_plt_info['tot_iter'][0]}\"\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        first_point_text += f\"\\nMax Depth: {a_plt_info['max_depth'][0]}\"\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    a_ax.text( 0.85*a_plt_info['x'][0], 0.82*a_plt_info['y'][0], first_point_text )\n",
    "    \n",
    "    # Add text to the last datapoint\n",
    "    last_point_text = f\"({a_plt_info['x'][-1]:0.2f}, {a_plt_info['y'][-1]:0.2f})\"\n",
    "    \n",
    "    try:\n",
    "        last_point_text += f\"\\nSolver: {a_plt_info['solver'][-1]}\"\n",
    "        last_point_text += f\"\\nTotal Iterations: {a_plt_info['tot_iter'][-1]}\"\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        last_point_text += f\"\\nMax Depth: {a_plt_info['max_depth'][-1]}\"\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    a_ax.text( 0.85*a_plt_info['x'][-1], 0.82*a_plt_info['y'][-1], last_point_text )\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Classification Performance results\n",
    "fig1 = plt.figure(figsize=(12,10))\n",
    "ax_list = []\n",
    "p_i = 0\n",
    "\n",
    "for p_info in p_info_list:\n",
    "    ax_list.append( fig1.add_subplot(2, math.ceil(len(p_info_list)/2), p_i+1) )\n",
    "    create_plot(ax_list[p_i], p_info)\n",
    "    p_i += 1\n",
    "    \n",
    "    \n",
    "# Save the image - use it for Summary of Analysis at the top of the notebook\n",
    "plt.savefig('docs/Comparison_DecisionTree_vs_LogisticRegression.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Solver</th>\n",
       "      <th>Iterations</th>\n",
       "      <th>Total Iterations</th>\n",
       "      <th>Max Tree Depth</th>\n",
       "      <th>Fit Time (ms)</th>\n",
       "      <th>Score-Testing Data</th>\n",
       "      <th>Score-Training Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5039</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iris</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>0.3984</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iris</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>0.4242</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iris</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0.3816</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.973214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iris</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3774</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.955357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Iris</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4141</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.669643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Iris</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>[7]</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.8474</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.964286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Iris</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>[12, 14, 14]</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.4624</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.946429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Iris</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>[32, 35, 31]</td>\n",
       "      <td>98.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.7461</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.946429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Iris</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>sag</td>\n",
       "      <td>[1000, 640, 1000]</td>\n",
       "      <td>2640.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.4382</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Iris</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>saga</td>\n",
       "      <td>[1000, 1000, 1000]</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.2359</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Voice</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>29.2341</td>\n",
       "      <td>0.970960</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Voice</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>21.1731</td>\n",
       "      <td>0.968434</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Voice</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>25.8690</td>\n",
       "      <td>0.973485</td>\n",
       "      <td>0.998316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Voice</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>15.6431</td>\n",
       "      <td>0.976010</td>\n",
       "      <td>0.981061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Voice</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>8.3096</td>\n",
       "      <td>0.963384</td>\n",
       "      <td>0.962542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Voice</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5574</td>\n",
       "      <td>0.955808</td>\n",
       "      <td>0.953283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Voice</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>[7]</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.7224</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.973064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Voice</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>[14]</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.6979</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.972222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Voice</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>[49]</td>\n",
       "      <td>49.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.6674</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.972222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Voice</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>sag</td>\n",
       "      <td>[90]</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>116.2488</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.972222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Voice</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>saga</td>\n",
       "      <td>[157]</td>\n",
       "      <td>157.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167.9294</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.972222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dataset              Classifier     Solver          Iterations  \\\n",
       "0     Iris  DecisionTreeClassifier        NaN                 NaN   \n",
       "1     Iris  DecisionTreeClassifier        NaN                 NaN   \n",
       "2     Iris  DecisionTreeClassifier        NaN                 NaN   \n",
       "3     Iris  DecisionTreeClassifier        NaN                 NaN   \n",
       "4     Iris  DecisionTreeClassifier        NaN                 NaN   \n",
       "5     Iris  DecisionTreeClassifier        NaN                 NaN   \n",
       "6     Iris      LogisticRegression  liblinear                 [7]   \n",
       "7     Iris      LogisticRegression  newton-cg        [12, 14, 14]   \n",
       "8     Iris      LogisticRegression      lbfgs        [32, 35, 31]   \n",
       "9     Iris      LogisticRegression        sag   [1000, 640, 1000]   \n",
       "10    Iris      LogisticRegression       saga  [1000, 1000, 1000]   \n",
       "11   Voice  DecisionTreeClassifier        NaN                 NaN   \n",
       "12   Voice  DecisionTreeClassifier        NaN                 NaN   \n",
       "13   Voice  DecisionTreeClassifier        NaN                 NaN   \n",
       "14   Voice  DecisionTreeClassifier        NaN                 NaN   \n",
       "15   Voice  DecisionTreeClassifier        NaN                 NaN   \n",
       "16   Voice  DecisionTreeClassifier        NaN                 NaN   \n",
       "17   Voice      LogisticRegression  liblinear                 [7]   \n",
       "18   Voice      LogisticRegression  newton-cg                [14]   \n",
       "19   Voice      LogisticRegression      lbfgs                [49]   \n",
       "20   Voice      LogisticRegression        sag                [90]   \n",
       "21   Voice      LogisticRegression       saga               [157]   \n",
       "\n",
       "    Total Iterations Max Tree Depth  Fit Time (ms)  Score-Testing Data  \\\n",
       "0                NaN           None         0.5039            0.973684   \n",
       "1                NaN             16         0.3984            0.973684   \n",
       "2                NaN              8         0.4242            0.947368   \n",
       "3                NaN              4         0.3816            0.973684   \n",
       "4                NaN              2         0.3774            0.947368   \n",
       "5                NaN              1         0.4141            0.657895   \n",
       "6                7.0            NaN        22.8474            0.947368   \n",
       "7               40.0            NaN        24.4624            0.947368   \n",
       "8               98.0            NaN        15.7461            0.947368   \n",
       "9             2640.0            NaN       100.4382            0.947368   \n",
       "10            3000.0            NaN        82.2359            0.973684   \n",
       "11               NaN           None        29.2341            0.970960   \n",
       "12               NaN             16        21.1731            0.968434   \n",
       "13               NaN              8        25.8690            0.973485   \n",
       "14               NaN              4        15.6431            0.976010   \n",
       "15               NaN              2         8.3096            0.963384   \n",
       "16               NaN              1         4.5574            0.955808   \n",
       "17               7.0            NaN        12.7224            0.977273   \n",
       "18              14.0            NaN        53.6979            0.977273   \n",
       "19              49.0            NaN        22.6674            0.977273   \n",
       "20              90.0            NaN       116.2488            0.977273   \n",
       "21             157.0            NaN       167.9294            0.977273   \n",
       "\n",
       "    Score-Training Data  \n",
       "0              1.000000  \n",
       "1              1.000000  \n",
       "2              1.000000  \n",
       "3              0.973214  \n",
       "4              0.955357  \n",
       "5              0.669643  \n",
       "6              0.964286  \n",
       "7              0.946429  \n",
       "8              0.946429  \n",
       "9              0.937500  \n",
       "10             0.937500  \n",
       "11             1.000000  \n",
       "12             1.000000  \n",
       "13             0.998316  \n",
       "14             0.981061  \n",
       "15             0.962542  \n",
       "16             0.953283  \n",
       "17             0.973064  \n",
       "18             0.972222  \n",
       "19             0.972222  \n",
       "20             0.972222  \n",
       "21             0.972222  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "nbpresent": {
   "slides": {
    "03210a56-863e-4749-b7ba-ed75bfceceee": {
     "id": "03210a56-863e-4749-b7ba-ed75bfceceee",
     "prev": "86b3b05f-6e9a-49dc-8a83-97f72c348c5f",
     "regions": {
      "2be9481c-cff7-4f32-b835-90f2a2cb989a": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "46550b81-7dd8-4efc-b710-0f10002c9f2b",
        "part": "whole"
       },
       "id": "2be9481c-cff7-4f32-b835-90f2a2cb989a"
      },
      "3f484569-30ec-4529-8d3c-ac88b8c6dbfb": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "2b83c32a-d7e2-4db6-b45f-afbbf028fe90",
        "part": "whole"
       },
       "id": "3f484569-30ec-4529-8d3c-ac88b8c6dbfb"
      }
     }
    },
    "22531930-3fc8-45ff-a4f1-32e94c1d1455": {
     "id": "22531930-3fc8-45ff-a4f1-32e94c1d1455",
     "prev": "8eb735f6-11af-4f77-a4ed-b637fb18ac08",
     "regions": {
      "1407c818-c9fd-470e-8260-6b6904d888de": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "664c64ef-5517-4725-95cb-874bbc7711c7",
        "part": "whole"
       },
       "id": "1407c818-c9fd-470e-8260-6b6904d888de"
      }
     }
    },
    "29c55765-6994-4dbf-b82f-117b4f1e0cee": {
     "id": "29c55765-6994-4dbf-b82f-117b4f1e0cee",
     "prev": "b7c25bc1-4dd7-421b-9951-0c0c403c176d",
     "regions": {
      "44583f15-ec4f-4aec-8e7c-f01652e954fc": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "7c23961d-86fe-4d07-bc58-6d61f03c3731",
        "part": "whole"
       },
       "id": "44583f15-ec4f-4aec-8e7c-f01652e954fc"
      }
     }
    },
    "39c5764b-ab2c-4aae-8500-dc39319e4d38": {
     "id": "39c5764b-ab2c-4aae-8500-dc39319e4d38",
     "prev": "22531930-3fc8-45ff-a4f1-32e94c1d1455",
     "regions": {
      "d0237596-8095-44dc-81c6-6d9c6b204684": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "348e164e-a000-4def-92c0-db93f9a617a1",
        "part": "whole"
       },
       "id": "d0237596-8095-44dc-81c6-6d9c6b204684"
      }
     }
    },
    "39e950f1-f2c4-422a-8f45-835c5c61e7e0": {
     "id": "39e950f1-f2c4-422a-8f45-835c5c61e7e0",
     "prev": "4b5f1824-db4a-4ef3-9515-a88d3f2276c1",
     "regions": {
      "0a72cc48-c38f-4e8c-94d3-3198eccde68a": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "c3820b22-bf55-4dca-ba8b-f08060567b6e",
        "part": "whole"
       },
       "id": "0a72cc48-c38f-4e8c-94d3-3198eccde68a"
      },
      "b49c6eca-318f-41b8-a7a5-a620d18f639c": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "aeeeb44d-7825-4050-b7ba-70813bd3396b",
        "part": "whole"
       },
       "id": "b49c6eca-318f-41b8-a7a5-a620d18f639c"
      }
     }
    },
    "4792c0cc-ccd4-48bf-9b0e-a3c1f0f3008d": {
     "id": "4792c0cc-ccd4-48bf-9b0e-a3c1f0f3008d",
     "prev": "39c5764b-ab2c-4aae-8500-dc39319e4d38",
     "regions": {
      "d4adae26-ff2f-4a81-ad91-fd3a9bfd965c": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "4d6b8af6-438e-4034-bda1-1f977cf12441",
        "part": "whole"
       },
       "id": "d4adae26-ff2f-4a81-ad91-fd3a9bfd965c"
      },
      "d75a8261-ee89-4f4d-b388-2f429e112f44": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "a3b6e99c-2c85-47da-b29b-3b53c3c309b8",
        "part": "whole"
       },
       "id": "d75a8261-ee89-4f4d-b388-2f429e112f44"
      }
     }
    },
    "4b5f1824-db4a-4ef3-9515-a88d3f2276c1": {
     "id": "4b5f1824-db4a-4ef3-9515-a88d3f2276c1",
     "prev": "e92a9020-6631-400a-aa50-46c1fa0a5f0c",
     "regions": {
      "2bd81133-11e3-48df-bf12-2d0a57949bca": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "69fab88f-0864-47cc-933b-eaffb638cbf3",
        "part": "whole"
       },
       "id": "2bd81133-11e3-48df-bf12-2d0a57949bca"
      },
      "d3322861-28ab-4f1e-8a1f-3a7f4d3da8c1": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "3810c2af-fdbe-4f01-bc9f-2bb1a8ae70c6",
        "part": "whole"
       },
       "id": "d3322861-28ab-4f1e-8a1f-3a7f4d3da8c1"
      }
     }
    },
    "57992fb9-2f74-4e8e-8772-7b9f04606a56": {
     "id": "57992fb9-2f74-4e8e-8772-7b9f04606a56",
     "prev": "595093b4-3f86-406c-abb5-aea78e1241b3",
     "regions": {
      "3b3c8191-9f7e-4ab2-afac-b2b47008484a": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "a6d0bdff-9bba-472e-b354-da47b8761dbe",
        "part": "whole"
       },
       "id": "3b3c8191-9f7e-4ab2-afac-b2b47008484a"
      }
     }
    },
    "5907f515-df93-4e86-82c6-b8721b6e6346": {
     "id": "5907f515-df93-4e86-82c6-b8721b6e6346",
     "prev": "39e950f1-f2c4-422a-8f45-835c5c61e7e0",
     "regions": {
      "22f9005a-ed7a-4399-b501-497565ada2da": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "2e255efc-6ae1-4554-b32f-9400b47007c9",
        "part": "whole"
       },
       "id": "22f9005a-ed7a-4399-b501-497565ada2da"
      },
      "82d64cef-48f7-413c-ad01-e7fa2921f7c0": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "711a40c8-c479-448b-a3bc-5c7ff8369838",
        "part": "whole"
       },
       "id": "82d64cef-48f7-413c-ad01-e7fa2921f7c0"
      },
      "d943d3ea-6cd3-4d4a-8914-7fea0231efda": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "9bfbb27b-cae0-4feb-809a-77718bb2e6a3",
        "part": "whole"
       },
       "id": "d943d3ea-6cd3-4d4a-8914-7fea0231efda"
      }
     }
    },
    "595093b4-3f86-406c-abb5-aea78e1241b3": {
     "id": "595093b4-3f86-406c-abb5-aea78e1241b3",
     "prev": "5907f515-df93-4e86-82c6-b8721b6e6346",
     "regions": {
      "3366a1dc-6c33-45f0-a97f-a2744ed0587f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "e54b79a1-316d-4fd1-ad5f-6cd580b51f99",
        "part": "whole"
       },
       "id": "3366a1dc-6c33-45f0-a97f-a2744ed0587f"
      },
      "40b6dba8-5994-4fd0-9ce5-9d36f3bb9f93": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "3d860568-b048-40f2-a64d-f585211d6c1c",
        "part": "whole"
       },
       "id": "40b6dba8-5994-4fd0-9ce5-9d36f3bb9f93"
      }
     }
    },
    "76838eab-c2c3-4ff3-b09f-854a7c74c6d4": {
     "id": "76838eab-c2c3-4ff3-b09f-854a7c74c6d4",
     "prev": null,
     "regions": {
      "b0032c00-1d89-4c94-a7a0-488f243c381e": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "0dc0cdcb-d8df-4a29-a0d2-a3cf6cc889ce",
        "part": "whole"
       },
       "id": "b0032c00-1d89-4c94-a7a0-488f243c381e"
      }
     }
    },
    "7a25817a-e5bc-4021-9c6b-61bc74dbdb92": {
     "id": "7a25817a-e5bc-4021-9c6b-61bc74dbdb92",
     "prev": "b04719fc-934a-404b-a642-dc732a3d1589",
     "regions": {
      "38d56409-500a-45cf-8e79-722d68d8fc38": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "335f050d-99af-43b3-a5ec-69fe896e48e2",
        "part": "whole"
       },
       "id": "38d56409-500a-45cf-8e79-722d68d8fc38"
      },
      "c838cb6d-409c-4c17-a1eb-3d7dc6aab32b": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "19ca6a7e-4b5d-4b0f-88c5-e68634abb65d",
        "part": "whole"
       },
       "id": "c838cb6d-409c-4c17-a1eb-3d7dc6aab32b"
      }
     }
    },
    "86b3b05f-6e9a-49dc-8a83-97f72c348c5f": {
     "id": "86b3b05f-6e9a-49dc-8a83-97f72c348c5f",
     "prev": "57992fb9-2f74-4e8e-8772-7b9f04606a56",
     "regions": {
      "49a41ef6-224d-46c1-bb81-254b8a4cee88": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "d7df6fa0-ce96-4073-b95d-ce78b3f4fdf1",
        "part": "whole"
       },
       "id": "49a41ef6-224d-46c1-bb81-254b8a4cee88"
      },
      "7ce316ab-4799-4e15-b095-374da21bc1aa": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "4a5226b5-d431-4cbe-86a6-291952a45a37",
        "part": "whole"
       },
       "id": "7ce316ab-4799-4e15-b095-374da21bc1aa"
      },
      "a7d701c6-61e3-48e3-8e0d-a4b318aef7d8": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "5e425283-82de-4c48-b2ae-31a1d6983849",
        "part": "whole"
       },
       "id": "a7d701c6-61e3-48e3-8e0d-a4b318aef7d8"
      },
      "e180cf23-71a7-46a8-8598-86a079bd7d78": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "28aaab45-1e14-4db5-9d2c-63b239cafe13",
        "part": "whole"
       },
       "id": "e180cf23-71a7-46a8-8598-86a079bd7d78"
      }
     }
    },
    "8eb735f6-11af-4f77-a4ed-b637fb18ac08": {
     "id": "8eb735f6-11af-4f77-a4ed-b637fb18ac08",
     "prev": "7a25817a-e5bc-4021-9c6b-61bc74dbdb92",
     "regions": {
      "ca38ef02-01f9-42cb-9e35-d67f8d665597": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "69b638ed-ed32-4824-bb81-df958c215a33",
        "part": "whole"
       },
       "id": "ca38ef02-01f9-42cb-9e35-d67f8d665597"
      },
      "fc52547b-a8f8-40e2-9397-5b18ca2b71b3": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "7317e4f2-150e-4336-ac48-d82641441aa8",
        "part": "whole"
       },
       "id": "fc52547b-a8f8-40e2-9397-5b18ca2b71b3"
      }
     }
    },
    "af2f5933-b31d-4d30-b08a-e4c09432b9bb": {
     "id": "af2f5933-b31d-4d30-b08a-e4c09432b9bb",
     "prev": "29c55765-6994-4dbf-b82f-117b4f1e0cee",
     "regions": {
      "479b436f-50bb-4c3a-9a4e-748e85eacde6": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "6d53481c-69ff-41a0-937e-4e8a39e2b2b5",
        "part": "whole"
       },
       "id": "479b436f-50bb-4c3a-9a4e-748e85eacde6"
      },
      "a02a5bdc-cab5-4ddc-aa9d-8ee5e0db6bd4": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "b0f8400f-71e1-4892-9012-88e54c053a36",
        "part": "whole"
       },
       "id": "a02a5bdc-cab5-4ddc-aa9d-8ee5e0db6bd4"
      }
     }
    },
    "b04719fc-934a-404b-a642-dc732a3d1589": {
     "id": "b04719fc-934a-404b-a642-dc732a3d1589",
     "prev": "af2f5933-b31d-4d30-b08a-e4c09432b9bb",
     "regions": {
      "701cdc94-3399-40dc-8e45-10d6edbf0959": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "fa78fa75-54cf-40d3-b52c-4b51c5070d9a",
        "part": "whole"
       },
       "id": "701cdc94-3399-40dc-8e45-10d6edbf0959"
      },
      "81f01069-a0c6-4ab1-98d1-d465e96aac6d": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "fb58a52c-71e9-402d-af86-eab194cf8050",
        "part": "whole"
       },
       "id": "81f01069-a0c6-4ab1-98d1-d465e96aac6d"
      },
      "ae73fc9b-89cf-4405-ab54-34e6c8b73a19": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "241f356d-567a-421d-b27c-7ce2d146d1bb",
        "part": "whole"
       },
       "id": "ae73fc9b-89cf-4405-ab54-34e6c8b73a19"
      }
     }
    },
    "b7c25bc1-4dd7-421b-9951-0c0c403c176d": {
     "id": "b7c25bc1-4dd7-421b-9951-0c0c403c176d",
     "prev": "76838eab-c2c3-4ff3-b09f-854a7c74c6d4",
     "regions": {
      "47f524f5-68f8-49df-9a61-61eab6cab03c": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "966e050d-5739-4ef9-a2ae-9a4957e14f3e",
        "part": "whole"
       },
       "id": "47f524f5-68f8-49df-9a61-61eab6cab03c"
      },
      "4b3ba01a-29e7-4e67-ac78-988162f7dde9": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "91401f60-44eb-42b2-86ea-c82b5e955ace",
        "part": "whole"
       },
       "id": "4b3ba01a-29e7-4e67-ac78-988162f7dde9"
      },
      "a47d9662-0a49-4b84-aae0-908067552ebd": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "6de4dae8-c949-4927-89a3-9741aba83e8d",
        "part": "whole"
       },
       "id": "a47d9662-0a49-4b84-aae0-908067552ebd"
      },
      "e64668fe-aafe-4e24-a46d-6a6266eeee77": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "7068c96d-f8f0-42bb-bdfd-dcbf9335323c",
        "part": "whole"
       },
       "id": "e64668fe-aafe-4e24-a46d-6a6266eeee77"
      }
     }
    },
    "d3ecec0a-67fe-4558-a268-50695fd7fe1c": {
     "id": "d3ecec0a-67fe-4558-a268-50695fd7fe1c",
     "prev": "fcda7de6-cb93-4b63-9dea-d5f23fecd968",
     "regions": {
      "b268bb57-2543-4b91-b9c0-84aa3cf09d5c": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "67aab8fa-45cd-4ede-8285-e3dad22d8b16",
        "part": "whole"
       },
       "id": "b268bb57-2543-4b91-b9c0-84aa3cf09d5c"
      }
     }
    },
    "e92a9020-6631-400a-aa50-46c1fa0a5f0c": {
     "id": "e92a9020-6631-400a-aa50-46c1fa0a5f0c",
     "prev": "ee94ae9b-9e13-414c-a017-db1d8913aaa8",
     "regions": {
      "bb15b4ea-132f-4146-ab77-93a4969c2904": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "7d5d2002-5cae-4d5f-8e2e-d5eaf5cd17da",
        "part": "whole"
       },
       "id": "bb15b4ea-132f-4146-ab77-93a4969c2904"
      }
     }
    },
    "ee94ae9b-9e13-414c-a017-db1d8913aaa8": {
     "id": "ee94ae9b-9e13-414c-a017-db1d8913aaa8",
     "prev": "f8fce519-927e-4fd0-88d8-23ece4403794",
     "regions": {
      "0b578bb1-2cd1-480b-8d65-dde0861851cb": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "f1c699bc-6717-4eb9-8e6d-66d433ba4618",
        "part": "whole"
       },
       "id": "0b578bb1-2cd1-480b-8d65-dde0861851cb"
      }
     }
    },
    "f8fce519-927e-4fd0-88d8-23ece4403794": {
     "id": "f8fce519-927e-4fd0-88d8-23ece4403794",
     "prev": "4792c0cc-ccd4-48bf-9b0e-a3c1f0f3008d",
     "regions": {
      "7510ae01-fe22-48b0-92cb-29b880cc85fc": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "e61ba538-5828-4a5a-a2c5-4fcceac35889",
        "part": "whole"
       },
       "id": "7510ae01-fe22-48b0-92cb-29b880cc85fc"
      }
     }
    },
    "fcda7de6-cb93-4b63-9dea-d5f23fecd968": {
     "id": "fcda7de6-cb93-4b63-9dea-d5f23fecd968",
     "prev": "03210a56-863e-4749-b7ba-ed75bfceceee",
     "regions": {
      "43f5b3bd-9e0c-4a98-a18c-1b9f7beaa3b8": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "318099ba-93dd-4c2c-a3ee-fc6622c472c8",
        "part": "whole"
       },
       "id": "43f5b3bd-9e0c-4a98-a18c-1b9f7beaa3b8"
      },
      "dbab9920-f08a-457a-949d-2c8289707798": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "8bb35ef7-00cc-4ad9-9dd4-6fac480df38e",
        "part": "whole"
       },
       "id": "dbab9920-f08a-457a-949d-2c8289707798"
      }
     }
    }
   },
   "themes": {}
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
